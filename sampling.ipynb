{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b557faa-4025-4472-8e6c-02e444fed0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c2a58-7cb4-4d43-ade9-3852a778064c",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e295ba-6fa0-413f-8165-f5a901c25c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(1_000)\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "test_size = 100\n",
    "\n",
    "# Prepare train/test sets\n",
    "test_set_idx = torch.randint(0, X.shape[0], (test_size, ))\n",
    "idx = torch.ones_like(y, dtype=bool)\n",
    "idx[test_set_idx] = False\n",
    "\n",
    "X_test, y_test = X[~idx], y[~idx]\n",
    "X = X[idx]\n",
    "y = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b273a51-9b9a-4fc8-b3e9-8b5b8ca90e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19658efc-5b98-45b0-8da5-ad818dc1067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6999543309211731\r"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for _ in range(epochs):\n",
    "    preds = linear(X)\n",
    "    preds = preds.softmax(1).max(1)[0]\n",
    "    loss = loss_fn(preds, y.float())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"loss: {}\\r\".format(loss.item()), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9013f5b-dba3-4d52-896d-394ae5bdcd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = torch.concat([x.flatten() for x in linear.parameters()])\n",
    "params = params.detach().numpy()\n",
    "plt.hist(params);\n",
    "plt.title(\"Weights distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2503a81-3a1a-4dc1-b119-69a28ef44409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, d_x, d_y):\n",
    "    preds = model(d_x).softmax(1).argmax(1)\n",
    "    score = preds == d_y\n",
    "    return score.sum() / len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48197c9-28f6-4fee-89b6-581ee558e2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3158)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(linear, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a949a139-0953-431e-b71f-c6d2d20ca2f5",
   "metadata": {},
   "source": [
    "def norm(x, mu, sigma):\n",
    "    denom = sigma * np.sqrt(2 * np.pi)\n",
    "    exp = -0.5 * np.power((x - mu) / sigma, 2)\n",
    "    return np.exp(exp) / denom"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4b6f918-74f9-4253-9f15-5638b7127fd7",
   "metadata": {},
   "source": [
    "def metropolis(f, x0, max_iter, burnin=1_000):\n",
    "    samples = []\n",
    "    burnin_count = 0\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        x_n = stats.norm.rvs(x0, 1, 1)[0]\n",
    "        alpha = f(x_n) / f(x0)\n",
    "        u = np.random.uniform(0, 1)\n",
    "        if u <= alpha:\n",
    "            # accept\n",
    "            x0 = x_n\n",
    "            if burnin_count >= burnin:\n",
    "                samples.append(x_n)\n",
    "            else:\n",
    "                burnin_count += 1\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc7e8b0c-473e-438f-ac2b-f35a140a4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params_in_model(model, params):\n",
    "    \"\"\"Helper function to load `params` inside `model`\n",
    "\n",
    "    **Note**: this method modifes `model` **in place**.\n",
    "    \"\"\"\n",
    "    total_params = len(params)\n",
    "    params_set = 0\n",
    "    with torch.no_grad():\n",
    "        for w_name, w in model.named_parameters():\n",
    "             # skip un-learnable params\n",
    "            if not w.requires_grad:\n",
    "                continue\n",
    "\n",
    "            setattr(model, w_name, torch.nn.Parameter(\n",
    "                torch.tensor(params[params_set: params_set + w.numel()],\n",
    "                             dtype=w.dtype).reshape(w.shape))\n",
    "            )\n",
    "            params_set += w.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0735cf8-bd9e-4610-950c-b9c1ad298214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_for_model(model, params_cdf, d_x, d_y, x0, max_iter, burnin=1_000, scale=1.0):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "    model :\n",
    "      the model to use to sample `P(D | theta)`.\n",
    "    params_cdf :\n",
    "      the cumulative densitify function of the parameter space. This is\n",
    "      used to `P(theta)` on each new param sample.\n",
    "    d_x :\n",
    "      the x dataset to use as D\n",
    "    d_y :\n",
    "      the label to use as D\n",
    "    x0 :\n",
    "      starting sample for the proposal density\n",
    "    max_iter :\n",
    "      the maximum number of iteration of the sampling\n",
    "    buring :\n",
    "      the number of sample to discard at the beginning of the sampling phase.\n",
    "    scale :\n",
    "      the scale factor to use to \"flatten\" the probability function. Useful to samples\n",
    "      values outside the center of the posterior.\n",
    "\n",
    "    Returns:\n",
    "      a list of (weight, h(theta)) couples, where h(theta) is defined as:\n",
    "            log(p(D | theta)) + log(p(theta))\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    burnin_count = 0\n",
    "\n",
    "    backup_model = {\n",
    "        name: p.clone()\n",
    "        for name, p in model.named_parameters()\n",
    "    }\n",
    "    total_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    random_noise = stats.norm(0, 1)\n",
    "    uniform = stats.uniform(-0.1, 0.2)\n",
    "\n",
    "    def f(new_param):\n",
    "        load_params_in_model(model, new_param)\n",
    "        with torch.no_grad():\n",
    "            p_dataset = model(d_x).softmax(1).gather(1, d_y.unsqueeze(0)).log().sum()\n",
    "            p_weights = np.log(params_cdf(new_param)).sum()\n",
    "            return p_dataset + p_weights\n",
    "\n",
    "    f_x0 = f(x0)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # perturbation\n",
    "        # x_n = x0 + random_noise.rvs(total_param) * 0.1\n",
    "        x_n = x0 + uniform.rvs(total_param)\n",
    "        # x_n = stats.multivariate_normal.rvs(x0, 0.5)\n",
    "        f_xn = f(x_n)   # h(theta) = log(P(D | theta)) + log(P(theta))\n",
    "        # f_x0 = f(x0)\n",
    "        # use diff because they're log-prob. Convert it back using 'exp'.\n",
    "        alpha = np.exp(f_xn - f_x0) * scale\n",
    "        u = np.random.uniform(0, 1)\n",
    "        if u <= alpha:\n",
    "            print(f\"Accepting with params: {f_xn=}, {f_x0=}, {alpha=}\")\n",
    "            # accept\n",
    "            x0 = x_n\n",
    "            f_x0 = f_xn\n",
    "            if burnin_count >= burnin:\n",
    "                samples.append((x_n, f_xn))\n",
    "            else:\n",
    "                burnin_count += 1\n",
    "\n",
    "    # Restore the model\n",
    "    with torch.no_grad():\n",
    "        for name, p in backup_model.items():\n",
    "            setattr(model, name, torch.nn.Parameter(p))\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78477e48-8e5f-47fd-8428-9d4005cd8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup model weights\n",
    "\n",
    "params = torch.concat([p.flatten() for p in linear.parameters()])\n",
    "params = params.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b179520d-0281-48e1-8b9f-d8c4cb4dcbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepting with params: f_xn=tensor(-753.6553), f_x0=tensor(-793.9651), alpha=tensor(1.9251e+17)\n",
      "Accepting with params: f_xn=tensor(-706.3381), f_x0=tensor(-753.6553), alpha=tensor(2.1270e+20)\n",
      "Accepting with params: f_xn=tensor(-646.1495), f_x0=tensor(-706.3381), alpha=tensor(8.2737e+25)\n",
      "Accepting with params: f_xn=tensor(-641.9973), f_x0=tensor(-646.1495), alpha=tensor(38.1474)\n",
      "Accepting with params: f_xn=tensor(-641.0546), f_x0=tensor(-641.9973), alpha=tensor(1.5401)\n",
      "Accepting with params: f_xn=tensor(-640.8036), f_x0=tensor(-641.0546), alpha=tensor(0.7712)\n",
      "Accepting with params: f_xn=tensor(-641.9055), f_x0=tensor(-640.8036), alpha=tensor(0.1993)\n",
      "Accepting with params: f_xn=tensor(-640.9108), f_x0=tensor(-641.9055), alpha=tensor(1.6224)\n",
      "Accepting with params: f_xn=tensor(-640.4437), f_x0=tensor(-640.9108), alpha=tensor(0.9572)\n",
      "Accepting with params: f_xn=tensor(-640.3748), f_x0=tensor(-640.4437), alpha=tensor(0.6428)\n",
      "Accepting with params: f_xn=tensor(-641.5062), f_x0=tensor(-640.3748), alpha=tensor(0.1935)\n",
      "Accepting with params: f_xn=tensor(-641.2447), f_x0=tensor(-641.5062), alpha=tensor(0.7793)\n",
      "Accepting with params: f_xn=tensor(-641.5050), f_x0=tensor(-641.2447), alpha=tensor(0.4625)\n",
      "Accepting with params: f_xn=tensor(-642.6691), f_x0=tensor(-641.5050), alpha=tensor(0.1873)\n",
      "Accepting with params: f_xn=tensor(-640.9534), f_x0=tensor(-642.6691), alpha=tensor(3.3363)\n",
      "Accepting with params: f_xn=tensor(-642.1660), f_x0=tensor(-640.9534), alpha=tensor(0.1785)\n",
      "Accepting with params: f_xn=tensor(-640.8083), f_x0=tensor(-642.1660), alpha=tensor(2.3323)\n",
      "Accepting with params: f_xn=tensor(-640.7426), f_x0=tensor(-640.8083), alpha=tensor(0.6408)\n",
      "Accepting with params: f_xn=tensor(-640.7642), f_x0=tensor(-640.7426), alpha=tensor(0.5871)\n",
      "Accepting with params: f_xn=tensor(-640.9297), f_x0=tensor(-640.7642), alpha=tensor(0.5085)\n",
      "Accepting with params: f_xn=tensor(-641.5655), f_x0=tensor(-640.9297), alpha=tensor(0.3177)\n",
      "Accepting with params: f_xn=tensor(-643.3241), f_x0=tensor(-641.5655), alpha=tensor(0.1034)\n",
      "Accepting with params: f_xn=tensor(-642.5424), f_x0=tensor(-643.3241), alpha=tensor(1.3112)\n",
      "Accepting with params: f_xn=tensor(-640.7721), f_x0=tensor(-642.5424), alpha=tensor(3.5234)\n",
      "Accepting with params: f_xn=tensor(-641.0366), f_x0=tensor(-640.7721), alpha=tensor(0.4605)\n",
      "Accepting with params: f_xn=tensor(-641.4990), f_x0=tensor(-641.0366), alpha=tensor(0.3779)\n",
      "Accepting with params: f_xn=tensor(-640.7510), f_x0=tensor(-641.4990), alpha=tensor(1.2676)\n",
      "Accepting with params: f_xn=tensor(-641.0619), f_x0=tensor(-640.7510), alpha=tensor(0.4397)\n",
      "Accepting with params: f_xn=tensor(-640.7593), f_x0=tensor(-641.0619), alpha=tensor(0.8120)\n",
      "Accepting with params: f_xn=tensor(-641.6428), f_x0=tensor(-640.7593), alpha=tensor(0.2480)\n",
      "Accepting with params: f_xn=tensor(-643.0109), f_x0=tensor(-641.6428), alpha=tensor(0.1528)\n",
      "Accepting with params: f_xn=tensor(-641.0948), f_x0=tensor(-643.0109), alpha=tensor(4.0763)\n",
      "Accepting with params: f_xn=tensor(-640.3484), f_x0=tensor(-641.0948), alpha=tensor(1.2657)\n",
      "Accepting with params: f_xn=tensor(-641.7238), f_x0=tensor(-640.3484), alpha=tensor(0.1516)\n",
      "Accepting with params: f_xn=tensor(-640.5179), f_x0=tensor(-641.7238), alpha=tensor(2.0038)\n",
      "Accepting with params: f_xn=tensor(-640.2714), f_x0=tensor(-640.5179), alpha=tensor(0.7677)\n",
      "Accepting with params: f_xn=tensor(-639.6809), f_x0=tensor(-640.2714), alpha=tensor(1.0830)\n",
      "Accepting with params: f_xn=tensor(-640.2562), f_x0=tensor(-639.6809), alpha=tensor(0.3375)\n",
      "Accepting with params: f_xn=tensor(-640.4194), f_x0=tensor(-640.2562), alpha=tensor(0.5096)\n",
      "Accepting with params: f_xn=tensor(-640.7129), f_x0=tensor(-640.4194), alpha=tensor(0.4474)\n",
      "Accepting with params: f_xn=tensor(-640.5651), f_x0=tensor(-640.7129), alpha=tensor(0.6955)\n",
      "Accepting with params: f_xn=tensor(-639.5367), f_x0=tensor(-640.5651), alpha=tensor(1.6779)\n",
      "Accepting with params: f_xn=tensor(-638.8911), f_x0=tensor(-639.5367), alpha=tensor(1.1443)\n",
      "Accepting with params: f_xn=tensor(-639.4094), f_x0=tensor(-638.8911), alpha=tensor(0.3573)\n",
      "Accepting with params: f_xn=tensor(-639.6885), f_x0=tensor(-639.4094), alpha=tensor(0.4539)\n",
      "Accepting with params: f_xn=tensor(-640.6466), f_x0=tensor(-639.6885), alpha=tensor(0.2302)\n",
      "Accepting with params: f_xn=tensor(-639.8826), f_x0=tensor(-640.6466), alpha=tensor(1.2881)\n",
      "Accepting with params: f_xn=tensor(-639.3028), f_x0=tensor(-639.8826), alpha=tensor(1.0714)\n",
      "Accepting with params: f_xn=tensor(-639.1993), f_x0=tensor(-639.3028), alpha=tensor(0.6654)\n",
      "Accepting with params: f_xn=tensor(-639.0275), f_x0=tensor(-639.1993), alpha=tensor(0.7125)\n",
      "Accepting with params: f_xn=tensor(-641.1846), f_x0=tensor(-639.0275), alpha=tensor(0.0694)\n",
      "Accepting with params: f_xn=tensor(-639.9907), f_x0=tensor(-641.1846), alpha=tensor(1.9800)\n",
      "Accepting with params: f_xn=tensor(-639.3240), f_x0=tensor(-639.9907), alpha=tensor(1.1687)\n",
      "Accepting with params: f_xn=tensor(-640.0856), f_x0=tensor(-639.3240), alpha=tensor(0.2801)\n",
      "Accepting with params: f_xn=tensor(-640.0309), f_x0=tensor(-640.0856), alpha=tensor(0.6338)\n",
      "Accepting with params: f_xn=tensor(-640.5566), f_x0=tensor(-640.0309), alpha=tensor(0.3547)\n",
      "Accepting with params: f_xn=tensor(-640.8102), f_x0=tensor(-640.5566), alpha=tensor(0.4656)\n",
      "Accepting with params: f_xn=tensor(-640.8228), f_x0=tensor(-640.8102), alpha=tensor(0.5925)\n",
      "Accepting with params: f_xn=tensor(-640.9714), f_x0=tensor(-640.8228), alpha=tensor(0.5171)\n",
      "Accepting with params: f_xn=tensor(-640.5985), f_x0=tensor(-640.9714), alpha=tensor(0.8712)\n",
      "Accepting with params: f_xn=tensor(-642.9351), f_x0=tensor(-640.5985), alpha=tensor(0.0580)\n",
      "Accepting with params: f_xn=tensor(-642.3030), f_x0=tensor(-642.9351), alpha=tensor(1.1289)\n",
      "Accepting with params: f_xn=tensor(-641.7083), f_x0=tensor(-642.3030), alpha=tensor(1.0876)\n",
      "Accepting with params: f_xn=tensor(-641.4762), f_x0=tensor(-641.7083), alpha=tensor(0.7567)\n",
      "Accepting with params: f_xn=tensor(-643.0861), f_x0=tensor(-641.4762), alpha=tensor(0.1199)\n",
      "Accepting with params: f_xn=tensor(-642.8625), f_x0=tensor(-643.0861), alpha=tensor(0.7503)\n",
      "Accepting with params: f_xn=tensor(-642.7148), f_x0=tensor(-642.8625), alpha=tensor(0.6955)\n",
      "Accepting with params: f_xn=tensor(-644.6998), f_x0=tensor(-642.7148), alpha=tensor(0.0824)\n",
      "Accepting with params: f_xn=tensor(-645.1816), f_x0=tensor(-644.6998), alpha=tensor(0.3706)\n",
      "Accepting with params: f_xn=tensor(-643.1092), f_x0=tensor(-645.1816), alpha=tensor(4.7663)\n",
      "Accepting with params: f_xn=tensor(-644.8220), f_x0=tensor(-643.1092), alpha=tensor(0.1082)\n",
      "Accepting with params: f_xn=tensor(-645.8547), f_x0=tensor(-644.8220), alpha=tensor(0.2136)\n",
      "Accepting with params: f_xn=tensor(-646.0280), f_x0=tensor(-645.8547), alpha=tensor(0.5046)\n",
      "Accepting with params: f_xn=tensor(-646.0471), f_x0=tensor(-646.0280), alpha=tensor(0.5886)\n",
      "Accepting with params: f_xn=tensor(-647.5803), f_x0=tensor(-646.0471), alpha=tensor(0.1295)\n",
      "Accepting with params: f_xn=tensor(-648.5502), f_x0=tensor(-647.5803), alpha=tensor(0.2275)\n",
      "Accepting with params: f_xn=tensor(-647.6581), f_x0=tensor(-648.5502), alpha=tensor(1.4641)\n",
      "Accepting with params: f_xn=tensor(-648.2842), f_x0=tensor(-647.6581), alpha=tensor(0.3208)\n",
      "Accepting with params: f_xn=tensor(-647.3480), f_x0=tensor(-648.2842), alpha=tensor(1.5303)\n",
      "Accepting with params: f_xn=tensor(-649.6991), f_x0=tensor(-647.3480), alpha=tensor(0.0572)\n",
      "Accepting with params: f_xn=tensor(-647.9636), f_x0=tensor(-649.6991), alpha=tensor(3.4032)\n",
      "Accepting with params: f_xn=tensor(-648.1713), f_x0=tensor(-647.9636), alpha=tensor(0.4875)\n",
      "Accepting with params: f_xn=tensor(-648.3192), f_x0=tensor(-648.1713), alpha=tensor(0.5175)\n",
      "Accepting with params: f_xn=tensor(-648.5549), f_x0=tensor(-648.3192), alpha=tensor(0.4740)\n",
      "Accepting with params: f_xn=tensor(-647.8819), f_x0=tensor(-648.5549), alpha=tensor(1.1760)\n",
      "Accepting with params: f_xn=tensor(-648.6260), f_x0=tensor(-647.8819), alpha=tensor(0.2851)\n",
      "Accepting with params: f_xn=tensor(-649.8235), f_x0=tensor(-648.6260), alpha=tensor(0.1812)\n",
      "Accepting with params: f_xn=tensor(-649.9677), f_x0=tensor(-649.8235), alpha=tensor(0.5195)\n",
      "Accepting with params: f_xn=tensor(-648.1976), f_x0=tensor(-649.9677), alpha=tensor(3.5228)\n",
      "Accepting with params: f_xn=tensor(-649.3902), f_x0=tensor(-648.1976), alpha=tensor(0.1821)\n",
      "Accepting with params: f_xn=tensor(-647.6954), f_x0=tensor(-649.3902), alpha=tensor(3.2672)\n",
      "Accepting with params: f_xn=tensor(-647.4263), f_x0=tensor(-647.6954), alpha=tensor(0.7853)\n",
      "Accepting with params: f_xn=tensor(-647.5317), f_x0=tensor(-647.4263), alpha=tensor(0.5400)\n",
      "Accepting with params: f_xn=tensor(-646.5792), f_x0=tensor(-647.5317), alpha=tensor(1.5552)\n",
      "Accepting with params: f_xn=tensor(-646.9781), f_x0=tensor(-646.5792), alpha=tensor(0.4026)\n",
      "Accepting with params: f_xn=tensor(-646.9468), f_x0=tensor(-646.9781), alpha=tensor(0.6191)\n",
      "Accepting with params: f_xn=tensor(-647.8506), f_x0=tensor(-646.9468), alpha=tensor(0.2430)\n",
      "Accepting with params: f_xn=tensor(-648.3151), f_x0=tensor(-647.8506), alpha=tensor(0.3771)\n",
      "Accepting with params: f_xn=tensor(-649.3008), f_x0=tensor(-648.3151), alpha=tensor(0.2239)\n",
      "Accepting with params: f_xn=tensor(-650.5270), f_x0=tensor(-649.3008), alpha=tensor(0.1760)\n",
      "Accepting with params: f_xn=tensor(-651.8772), f_x0=tensor(-650.5270), alpha=tensor(0.1555)\n",
      "Accepting with params: f_xn=tensor(-650.7676), f_x0=tensor(-651.8772), alpha=tensor(1.8198)\n",
      "Accepting with params: f_xn=tensor(-649.6544), f_x0=tensor(-650.7676), alpha=tensor(1.8265)\n",
      "Accepting with params: f_xn=tensor(-649.8671), f_x0=tensor(-649.6544), alpha=tensor(0.4850)\n",
      "Accepting with params: f_xn=tensor(-649.8384), f_x0=tensor(-649.8671), alpha=tensor(0.6175)\n",
      "Accepting with params: f_xn=tensor(-651.3635), f_x0=tensor(-649.8384), alpha=tensor(0.1306)\n",
      "Accepting with params: f_xn=tensor(-650.8700), f_x0=tensor(-651.3635), alpha=tensor(0.9829)\n",
      "Accepting with params: f_xn=tensor(-650.2130), f_x0=tensor(-650.8700), alpha=tensor(1.1574)\n",
      "Accepting with params: f_xn=tensor(-652.2485), f_x0=tensor(-650.2130), alpha=tensor(0.0784)\n",
      "Accepting with params: f_xn=tensor(-650.3035), f_x0=tensor(-652.2485), alpha=tensor(4.1960)\n",
      "Accepting with params: f_xn=tensor(-648.9146), f_x0=tensor(-650.3035), alpha=tensor(2.4063)\n",
      "Accepting with params: f_xn=tensor(-647.8563), f_x0=tensor(-648.9146), alpha=tensor(1.7290)\n",
      "Accepting with params: f_xn=tensor(-650.5371), f_x0=tensor(-647.8563), alpha=tensor(0.0411)\n",
      "Accepting with params: f_xn=tensor(-649.8751), f_x0=tensor(-650.5371), alpha=tensor(1.1633)\n",
      "Accepting with params: f_xn=tensor(-649.0502), f_x0=tensor(-649.8751), alpha=tensor(1.3689)\n",
      "Accepting with params: f_xn=tensor(-648.3054), f_x0=tensor(-649.0502), alpha=tensor(1.2637)\n",
      "Accepting with params: f_xn=tensor(-648.0894), f_x0=tensor(-648.3054), alpha=tensor(0.7446)\n",
      "Accepting with params: f_xn=tensor(-647.9200), f_x0=tensor(-648.0894), alpha=tensor(0.7108)\n",
      "Accepting with params: f_xn=tensor(-648.4139), f_x0=tensor(-647.9200), alpha=tensor(0.3661)\n",
      "Accepting with params: f_xn=tensor(-647.5546), f_x0=tensor(-648.4139), alpha=tensor(1.4168)\n",
      "Accepting with params: f_xn=tensor(-647.9136), f_x0=tensor(-647.5546), alpha=tensor(0.4190)\n",
      "Accepting with params: f_xn=tensor(-647.4929), f_x0=tensor(-647.9136), alpha=tensor(0.9138)\n",
      "Accepting with params: f_xn=tensor(-646.5800), f_x0=tensor(-647.4929), alpha=tensor(1.4948)\n",
      "Accepting with params: f_xn=tensor(-646.8659), f_x0=tensor(-646.5800), alpha=tensor(0.4508)\n",
      "Accepting with params: f_xn=tensor(-646.8639), f_x0=tensor(-646.8659), alpha=tensor(0.6012)\n",
      "Accepting with params: f_xn=tensor(-646.8058), f_x0=tensor(-646.8639), alpha=tensor(0.6359)\n",
      "Accepting with params: f_xn=tensor(-646.8816), f_x0=tensor(-646.8058), alpha=tensor(0.5562)\n",
      "Accepting with params: f_xn=tensor(-646.9025), f_x0=tensor(-646.8816), alpha=tensor(0.5876)\n",
      "Accepting with params: f_xn=tensor(-646.5956), f_x0=tensor(-646.9025), alpha=tensor(0.8156)\n",
      "Accepting with params: f_xn=tensor(-645.8468), f_x0=tensor(-646.5956), alpha=tensor(1.2687)\n",
      "Accepting with params: f_xn=tensor(-646.6997), f_x0=tensor(-645.8468), alpha=tensor(0.2557)\n",
      "Accepting with params: f_xn=tensor(-645.4681), f_x0=tensor(-646.6997), alpha=tensor(2.0560)\n",
      "Accepting with params: f_xn=tensor(-646.7809), f_x0=tensor(-645.4681), alpha=tensor(0.1614)\n",
      "Accepting with params: f_xn=tensor(-648.1752), f_x0=tensor(-646.7809), alpha=tensor(0.1488)\n",
      "Accepting with params: f_xn=tensor(-647.7707), f_x0=tensor(-648.1752), alpha=tensor(0.8991)\n",
      "Accepting with params: f_xn=tensor(-646.4338), f_x0=tensor(-647.7707), alpha=tensor(2.2842)\n",
      "Accepting with params: f_xn=tensor(-646.7608), f_x0=tensor(-646.4338), alpha=tensor(0.4327)\n",
      "Accepting with params: f_xn=tensor(-646.2476), f_x0=tensor(-646.7608), alpha=tensor(1.0024)\n",
      "Accepting with params: f_xn=tensor(-645.5052), f_x0=tensor(-646.2476), alpha=tensor(1.2606)\n",
      "Accepting with params: f_xn=tensor(-646.3752), f_x0=tensor(-645.5052), alpha=tensor(0.2514)\n",
      "Accepting with params: f_xn=tensor(-646.0967), f_x0=tensor(-646.3752), alpha=tensor(0.7927)\n",
      "Accepting with params: f_xn=tensor(-646.9809), f_x0=tensor(-646.0967), alpha=tensor(0.2478)\n",
      "Accepting with params: f_xn=tensor(-647.2474), f_x0=tensor(-646.9809), alpha=tensor(0.4596)\n",
      "Accepting with params: f_xn=tensor(-645.7886), f_x0=tensor(-647.2474), alpha=tensor(2.5806)\n",
      "Accepting with params: f_xn=tensor(-644.8773), f_x0=tensor(-645.7886), alpha=tensor(1.4926)\n",
      "Accepting with params: f_xn=tensor(-645.3025), f_x0=tensor(-644.8773), alpha=tensor(0.3922)\n",
      "Accepting with params: f_xn=tensor(-644.9769), f_x0=tensor(-645.3025), alpha=tensor(0.8309)\n",
      "Accepting with params: f_xn=tensor(-644.3558), f_x0=tensor(-644.9769), alpha=tensor(1.1166)\n",
      "Accepting with params: f_xn=tensor(-645.1478), f_x0=tensor(-644.3558), alpha=tensor(0.2717)\n",
      "Accepting with params: f_xn=tensor(-645.9987), f_x0=tensor(-645.1478), alpha=tensor(0.2562)\n",
      "Accepting with params: f_xn=tensor(-644.4413), f_x0=tensor(-645.9987), alpha=tensor(2.8476)\n",
      "Accepting with params: f_xn=tensor(-644.2231), f_x0=tensor(-644.4413), alpha=tensor(0.7463)\n",
      "Accepting with params: f_xn=tensor(-645.4774), f_x0=tensor(-644.2231), alpha=tensor(0.1712)\n",
      "Accepting with params: f_xn=tensor(-644.3944), f_x0=tensor(-645.4774), alpha=tensor(1.7721)\n",
      "Accepting with params: f_xn=tensor(-646.3375), f_x0=tensor(-644.3944), alpha=tensor(0.0860)\n",
      "Accepting with params: f_xn=tensor(-646.5173), f_x0=tensor(-646.3375), alpha=tensor(0.5013)\n",
      "Accepting with params: f_xn=tensor(-645.0750), f_x0=tensor(-646.5173), alpha=tensor(2.5383)\n",
      "Accepting with params: f_xn=tensor(-644.1495), f_x0=tensor(-645.0750), alpha=tensor(1.5137)\n",
      "Accepting with params: f_xn=tensor(-644.0049), f_x0=tensor(-644.1495), alpha=tensor(0.6933)\n",
      "Accepting with params: f_xn=tensor(-642.6773), f_x0=tensor(-644.0049), alpha=tensor(2.2633)\n",
      "Accepting with params: f_xn=tensor(-642.4272), f_x0=tensor(-642.6773), alpha=tensor(0.7705)\n",
      "Accepting with params: f_xn=tensor(-642.3407), f_x0=tensor(-642.4272), alpha=tensor(0.6542)\n",
      "Accepting with params: f_xn=tensor(-642.9385), f_x0=tensor(-642.3407), alpha=tensor(0.3300)\n",
      "Accepting with params: f_xn=tensor(-641.0082), f_x0=tensor(-642.9385), alpha=tensor(4.1349)\n",
      "Accepting with params: f_xn=tensor(-641.3225), f_x0=tensor(-641.0082), alpha=tensor(0.4382)\n",
      "Accepting with params: f_xn=tensor(-640.0113), f_x0=tensor(-641.3225), alpha=tensor(2.2264)\n",
      "Accepting with params: f_xn=tensor(-639.4599), f_x0=tensor(-640.0113), alpha=tensor(1.0414)\n",
      "Accepting with params: f_xn=tensor(-641.1406), f_x0=tensor(-639.4599), alpha=tensor(0.1117)\n",
      "Accepting with params: f_xn=tensor(-641.5849), f_x0=tensor(-641.1406), alpha=tensor(0.3848)\n",
      "Accepting with params: f_xn=tensor(-640.9410), f_x0=tensor(-641.5849), alpha=tensor(1.1424)\n",
      "Accepting with params: f_xn=tensor(-640.4642), f_x0=tensor(-640.9410), alpha=tensor(0.9666)\n",
      "Accepting with params: f_xn=tensor(-639.2899), f_x0=tensor(-640.4642), alpha=tensor(1.9414)\n",
      "Accepting with params: f_xn=tensor(-639.4274), f_x0=tensor(-639.2899), alpha=tensor(0.5229)\n",
      "Accepting with params: f_xn=tensor(-639.4976), f_x0=tensor(-639.4274), alpha=tensor(0.5593)\n",
      "Accepting with params: f_xn=tensor(-639.2076), f_x0=tensor(-639.4976), alpha=tensor(0.8018)\n",
      "Accepting with params: f_xn=tensor(-639.4279), f_x0=tensor(-639.2076), alpha=tensor(0.4813)\n",
      "Accepting with params: f_xn=tensor(-640.0668), f_x0=tensor(-639.4279), alpha=tensor(0.3167)\n",
      "Accepting with params: f_xn=tensor(-640.6075), f_x0=tensor(-640.0668), alpha=tensor(0.3494)\n",
      "Accepting with params: f_xn=tensor(-640.6806), f_x0=tensor(-640.6075), alpha=tensor(0.5577)\n",
      "Accepting with params: f_xn=tensor(-640.2847), f_x0=tensor(-640.6806), alpha=tensor(0.8914)\n",
      "Accepting with params: f_xn=tensor(-641.7292), f_x0=tensor(-640.2847), alpha=tensor(0.1415)\n",
      "Accepting with params: f_xn=tensor(-641.0938), f_x0=tensor(-641.7292), alpha=tensor(1.1328)\n",
      "Accepting with params: f_xn=tensor(-640.7479), f_x0=tensor(-641.0938), alpha=tensor(0.8479)\n",
      "Accepting with params: f_xn=tensor(-640.6434), f_x0=tensor(-640.7479), alpha=tensor(0.6661)\n",
      "Accepting with params: f_xn=tensor(-640.5677), f_x0=tensor(-640.6434), alpha=tensor(0.6471)\n",
      "Accepting with params: f_xn=tensor(-641.8196), f_x0=tensor(-640.5677), alpha=tensor(0.1716)\n",
      "Accepting with params: f_xn=tensor(-641.4224), f_x0=tensor(-641.8196), alpha=tensor(0.8927)\n",
      "Accepting with params: f_xn=tensor(-641.6108), f_x0=tensor(-641.4224), alpha=tensor(0.4969)\n",
      "Accepting with params: f_xn=tensor(-641.8044), f_x0=tensor(-641.6108), alpha=tensor(0.4944)\n",
      "Accepting with params: f_xn=tensor(-642.6297), f_x0=tensor(-641.8044), alpha=tensor(0.2629)\n",
      "Accepting with params: f_xn=tensor(-643.4672), f_x0=tensor(-642.6297), alpha=tensor(0.2597)\n",
      "Accepting with params: f_xn=tensor(-643.6272), f_x0=tensor(-643.4672), alpha=tensor(0.5113)\n",
      "Accepting with params: f_xn=tensor(-642.2260), f_x0=tensor(-643.6272), alpha=tensor(2.4362)\n",
      "Accepting with params: f_xn=tensor(-641.8710), f_x0=tensor(-642.2260), alpha=tensor(0.8557)\n",
      "Accepting with params: f_xn=tensor(-640.9504), f_x0=tensor(-641.8710), alpha=tensor(1.5064)\n",
      "Accepting with params: f_xn=tensor(-640.5463), f_x0=tensor(-640.9504), alpha=tensor(0.8988)\n",
      "Accepting with params: f_xn=tensor(-640.2285), f_x0=tensor(-640.5463), alpha=tensor(0.8245)\n",
      "Accepting with params: f_xn=tensor(-638.8940), f_x0=tensor(-640.2285), alpha=tensor(2.2788)\n",
      "Accepting with params: f_xn=tensor(-640.0872), f_x0=tensor(-638.8940), alpha=tensor(0.1819)\n",
      "Accepting with params: f_xn=tensor(-639.9345), f_x0=tensor(-640.0872), alpha=tensor(0.6990)\n",
      "Accepting with params: f_xn=tensor(-639.7748), f_x0=tensor(-639.9345), alpha=tensor(0.7039)\n",
      "Accepting with params: f_xn=tensor(-639.9255), f_x0=tensor(-639.7748), alpha=tensor(0.5161)\n",
      "Accepting with params: f_xn=tensor(-639.9178), f_x0=tensor(-639.9255), alpha=tensor(0.6047)\n",
      "Accepting with params: f_xn=tensor(-640.8248), f_x0=tensor(-639.9178), alpha=tensor(0.2422)\n",
      "Accepting with params: f_xn=tensor(-640.7000), f_x0=tensor(-640.8248), alpha=tensor(0.6798)\n",
      "Accepting with params: f_xn=tensor(-640.8046), f_x0=tensor(-640.7000), alpha=tensor(0.5404)\n",
      "Accepting with params: f_xn=tensor(-640.6982), f_x0=tensor(-640.8046), alpha=tensor(0.6674)\n",
      "Accepting with params: f_xn=tensor(-639.7822), f_x0=tensor(-640.6982), alpha=tensor(1.4996)\n",
      "Accepting with params: f_xn=tensor(-640.0201), f_x0=tensor(-639.7822), alpha=tensor(0.4730)\n",
      "Accepting with params: f_xn=tensor(-643.1001), f_x0=tensor(-640.0201), alpha=tensor(0.0276)\n",
      "Accepting with params: f_xn=tensor(-640.0646), f_x0=tensor(-643.1001), alpha=tensor(12.4863)\n",
      "Accepting with params: f_xn=tensor(-640.4963), f_x0=tensor(-640.0646), alpha=tensor(0.3897)\n",
      "Accepting with params: f_xn=tensor(-640.0261), f_x0=tensor(-640.4963), alpha=tensor(0.9602)\n",
      "Accepting with params: f_xn=tensor(-640.6354), f_x0=tensor(-640.0261), alpha=tensor(0.3262)\n",
      "Accepting with params: f_xn=tensor(-639.7354), f_x0=tensor(-640.6354), alpha=tensor(1.4759)\n",
      "Accepting with params: f_xn=tensor(-639.8392), f_x0=tensor(-639.7354), alpha=tensor(0.5408)\n",
      "Accepting with params: f_xn=tensor(-640.1603), f_x0=tensor(-639.8392), alpha=tensor(0.4352)\n",
      "Accepting with params: f_xn=tensor(-640.0482), f_x0=tensor(-640.1603), alpha=tensor(0.6712)\n",
      "Accepting with params: f_xn=tensor(-640.4263), f_x0=tensor(-640.0482), alpha=tensor(0.4111)\n",
      "Accepting with params: f_xn=tensor(-639.2541), f_x0=tensor(-640.4263), alpha=tensor(1.9375)\n",
      "Accepting with params: f_xn=tensor(-638.9866), f_x0=tensor(-639.2541), alpha=tensor(0.7840)\n",
      "Accepting with params: f_xn=tensor(-638.1437), f_x0=tensor(-638.9866), alpha=tensor(1.3938)\n",
      "Accepting with params: f_xn=tensor(-639.7278), f_x0=tensor(-638.1437), alpha=tensor(0.1231)\n",
      "Accepting with params: f_xn=tensor(-638.7833), f_x0=tensor(-639.7278), alpha=tensor(1.5430)\n",
      "Accepting with params: f_xn=tensor(-638.4291), f_x0=tensor(-638.7833), alpha=tensor(0.8550)\n",
      "Accepting with params: f_xn=tensor(-638.0315), f_x0=tensor(-638.4291), alpha=tensor(0.8930)\n",
      "Accepting with params: f_xn=tensor(-639.6029), f_x0=tensor(-638.0315), alpha=tensor(0.1247)\n",
      "Accepting with params: f_xn=tensor(-641.5936), f_x0=tensor(-639.6029), alpha=tensor(0.0820)\n",
      "Accepting with params: f_xn=tensor(-642.5872), f_x0=tensor(-641.5936), alpha=tensor(0.2222)\n",
      "Accepting with params: f_xn=tensor(-642.5793), f_x0=tensor(-642.5872), alpha=tensor(0.6047)\n",
      "Accepting with params: f_xn=tensor(-640.1877), f_x0=tensor(-642.5793), alpha=tensor(6.5582)\n",
      "Accepting with params: f_xn=tensor(-639.5235), f_x0=tensor(-640.1877), alpha=tensor(1.1658)\n",
      "Accepting with params: f_xn=tensor(-639.1533), f_x0=tensor(-639.5235), alpha=tensor(0.8688)\n",
      "Accepting with params: f_xn=tensor(-639.0112), f_x0=tensor(-639.1533), alpha=tensor(0.6916)\n",
      "Accepting with params: f_xn=tensor(-638.5257), f_x0=tensor(-639.0112), alpha=tensor(0.9750)\n",
      "Accepting with params: f_xn=tensor(-639.6335), f_x0=tensor(-638.5257), alpha=tensor(0.1982)\n",
      "Accepting with params: f_xn=tensor(-638.6674), f_x0=tensor(-639.6335), alpha=tensor(1.5765)\n",
      "Accepting with params: f_xn=tensor(-639.3544), f_x0=tensor(-638.6674), alpha=tensor(0.3018)\n",
      "Accepting with params: f_xn=tensor(-638.4255), f_x0=tensor(-639.3544), alpha=tensor(1.5191)\n",
      "Accepting with params: f_xn=tensor(-637.5033), f_x0=tensor(-638.4255), alpha=tensor(1.5089)\n",
      "Accepting with params: f_xn=tensor(-637.2540), f_x0=tensor(-637.5033), alpha=tensor(0.7699)\n",
      "Accepting with params: f_xn=tensor(-636.6514), f_x0=tensor(-637.2540), alpha=tensor(1.0962)\n",
      "Accepting with params: f_xn=tensor(-636.8655), f_x0=tensor(-636.6514), alpha=tensor(0.4844)\n",
      "Accepting with params: f_xn=tensor(-636.6772), f_x0=tensor(-636.8655), alpha=tensor(0.7243)\n",
      "Accepting with params: f_xn=tensor(-639.2409), f_x0=tensor(-636.6772), alpha=tensor(0.0462)\n",
      "Accepting with params: f_xn=tensor(-636.5867), f_x0=tensor(-639.2409), alpha=tensor(8.5280)\n",
      "Accepting with params: f_xn=tensor(-636.9567), f_x0=tensor(-636.5867), alpha=tensor(0.4145)\n",
      "Accepting with params: f_xn=tensor(-636.0767), f_x0=tensor(-636.9567), alpha=tensor(1.4465)\n",
      "Accepting with params: f_xn=tensor(-636.5313), f_x0=tensor(-636.0767), alpha=tensor(0.3808)\n",
      "Accepting with params: f_xn=tensor(-638.6490), f_x0=tensor(-636.5313), alpha=tensor(0.0722)\n",
      "Accepting with params: f_xn=tensor(-639.0609), f_x0=tensor(-638.6490), alpha=tensor(0.3975)\n",
      "Accepting with params: f_xn=tensor(-639.4013), f_x0=tensor(-639.0609), alpha=tensor(0.4269)\n",
      "Accepting with params: f_xn=tensor(-638.7844), f_x0=tensor(-639.4013), alpha=tensor(1.1119)\n",
      "Accepting with params: f_xn=tensor(-637.1481), f_x0=tensor(-638.7844), alpha=tensor(3.0817)\n",
      "Accepting with params: f_xn=tensor(-636.6161), f_x0=tensor(-637.1481), alpha=tensor(1.0214)\n",
      "Accepting with params: f_xn=tensor(-636.1764), f_x0=tensor(-636.6161), alpha=tensor(0.9313)\n",
      "Accepting with params: f_xn=tensor(-635.7552), f_x0=tensor(-636.1764), alpha=tensor(0.9142)\n",
      "Accepting with params: f_xn=tensor(-636.2568), f_x0=tensor(-635.7552), alpha=tensor(0.3634)\n",
      "Accepting with params: f_xn=tensor(-636.5067), f_x0=tensor(-636.2568), alpha=tensor(0.4673)\n",
      "Accepting with params: f_xn=tensor(-635.9138), f_x0=tensor(-636.5067), alpha=tensor(1.0855)\n",
      "Accepting with params: f_xn=tensor(-635.8607), f_x0=tensor(-635.9138), alpha=tensor(0.6327)\n",
      "Accepting with params: f_xn=tensor(-636.0325), f_x0=tensor(-635.8607), alpha=tensor(0.5053)\n",
      "Accepting with params: f_xn=tensor(-635.8207), f_x0=tensor(-636.0325), alpha=tensor(0.7415)\n",
      "Accepting with params: f_xn=tensor(-636.1059), f_x0=tensor(-635.8207), alpha=tensor(0.4511)\n",
      "Accepting with params: f_xn=tensor(-635.8566), f_x0=tensor(-636.1059), alpha=tensor(0.7699)\n",
      "Accepting with params: f_xn=tensor(-635.1537), f_x0=tensor(-635.8566), alpha=tensor(1.2117)\n",
      "Accepting with params: f_xn=tensor(-635.4971), f_x0=tensor(-635.1537), alpha=tensor(0.4256)\n",
      "Accepting with params: f_xn=tensor(-635.0015), f_x0=tensor(-635.4971), alpha=tensor(0.9848)\n",
      "Accepting with params: f_xn=tensor(-634.7582), f_x0=tensor(-635.0015), alpha=tensor(0.7653)\n",
      "Accepting with params: f_xn=tensor(-634.6736), f_x0=tensor(-634.7582), alpha=tensor(0.6530)\n",
      "Accepting with params: f_xn=tensor(-634.3005), f_x0=tensor(-634.6736), alpha=tensor(0.8713)\n",
      "Accepting with params: f_xn=tensor(-635.1994), f_x0=tensor(-634.3005), alpha=tensor(0.2442)\n",
      "Accepting with params: f_xn=tensor(-635.1796), f_x0=tensor(-635.1994), alpha=tensor(0.6120)\n",
      "Accepting with params: f_xn=tensor(-635.4343), f_x0=tensor(-635.1796), alpha=tensor(0.4651)\n",
      "Accepting with params: f_xn=tensor(-634.9687), f_x0=tensor(-635.4343), alpha=tensor(0.9558)\n",
      "Accepting with params: f_xn=tensor(-634.0537), f_x0=tensor(-634.9687), alpha=tensor(1.4980)\n",
      "Accepting with params: f_xn=tensor(-634.1014), f_x0=tensor(-634.0537), alpha=tensor(0.5721)\n",
      "Accepting with params: f_xn=tensor(-633.9631), f_x0=tensor(-634.1014), alpha=tensor(0.6890)\n",
      "Accepting with params: f_xn=tensor(-634.9650), f_x0=tensor(-633.9631), alpha=tensor(0.2203)\n",
      "Accepting with params: f_xn=tensor(-635.3267), f_x0=tensor(-634.9650), alpha=tensor(0.4179)\n",
      "Accepting with params: f_xn=tensor(-636.0698), f_x0=tensor(-635.3267), alpha=tensor(0.2854)\n",
      "Accepting with params: f_xn=tensor(-634.6190), f_x0=tensor(-636.0698), alpha=tensor(2.5599)\n",
      "Accepting with params: f_xn=tensor(-635.0122), f_x0=tensor(-634.6190), alpha=tensor(0.4049)\n",
      "Accepting with params: f_xn=tensor(-635.1447), f_x0=tensor(-635.0122), alpha=tensor(0.5256)\n",
      "Accepting with params: f_xn=tensor(-636.3370), f_x0=tensor(-635.1447), alpha=tensor(0.1821)\n",
      "Accepting with params: f_xn=tensor(-635.3119), f_x0=tensor(-636.3370), alpha=tensor(1.6724)\n",
      "Accepting with params: f_xn=tensor(-635.0315), f_x0=tensor(-635.3119), alpha=tensor(0.7942)\n",
      "Accepting with params: f_xn=tensor(-635.0156), f_x0=tensor(-635.0315), alpha=tensor(0.6096)\n",
      "Accepting with params: f_xn=tensor(-634.6565), f_x0=tensor(-635.0156), alpha=tensor(0.8593)\n",
      "Accepting with params: f_xn=tensor(-634.2101), f_x0=tensor(-634.6565), alpha=tensor(0.9376)\n",
      "Accepting with params: f_xn=tensor(-636.7999), f_x0=tensor(-634.2101), alpha=tensor(0.0450)\n",
      "Accepting with params: f_xn=tensor(-637.0714), f_x0=tensor(-636.7999), alpha=tensor(0.4573)\n",
      "Accepting with params: f_xn=tensor(-637.2274), f_x0=tensor(-637.0714), alpha=tensor(0.5133)\n",
      "Accepting with params: f_xn=tensor(-636.5369), f_x0=tensor(-637.2274), alpha=tensor(1.1969)\n",
      "Accepting with params: f_xn=tensor(-634.1199), f_x0=tensor(-636.5369), alpha=tensor(6.7273)\n",
      "Accepting with params: f_xn=tensor(-635.6615), f_x0=tensor(-634.1199), alpha=tensor(0.1284)\n",
      "Accepting with params: f_xn=tensor(-634.6616), f_x0=tensor(-635.6615), alpha=tensor(1.6308)\n",
      "Accepting with params: f_xn=tensor(-634.3174), f_x0=tensor(-634.6616), alpha=tensor(0.8465)\n",
      "Accepting with params: f_xn=tensor(-634.8491), f_x0=tensor(-634.3174), alpha=tensor(0.3525)\n",
      "Accepting with params: f_xn=tensor(-635.1456), f_x0=tensor(-634.8491), alpha=tensor(0.4460)\n",
      "Accepting with params: f_xn=tensor(-635.6125), f_x0=tensor(-635.1456), alpha=tensor(0.3762)\n",
      "Accepting with params: f_xn=tensor(-634.8397), f_x0=tensor(-635.6125), alpha=tensor(1.2996)\n",
      "Accepting with params: f_xn=tensor(-635.3475), f_x0=tensor(-634.8397), alpha=tensor(0.3611)\n",
      "Accepting with params: f_xn=tensor(-636.0474), f_x0=tensor(-635.3475), alpha=tensor(0.2980)\n",
      "Accepting with params: f_xn=tensor(-634.5027), f_x0=tensor(-636.0474), alpha=tensor(2.8117)\n",
      "Accepting with params: f_xn=tensor(-634.4489), f_x0=tensor(-634.5027), alpha=tensor(0.6332)\n",
      "Accepting with params: f_xn=tensor(-636.3213), f_x0=tensor(-634.4489), alpha=tensor(0.0923)\n",
      "Accepting with params: f_xn=tensor(-634.4843), f_x0=tensor(-636.3213), alpha=tensor(3.7665)\n",
      "Accepting with params: f_xn=tensor(-637.4896), f_x0=tensor(-634.4843), alpha=tensor(0.0297)\n",
      "Accepting with params: f_xn=tensor(-634.6895), f_x0=tensor(-637.4896), alpha=tensor(9.8679)\n",
      "Accepting with params: f_xn=tensor(-636.3199), f_x0=tensor(-634.6895), alpha=tensor(0.1175)\n",
      "Accepting with params: f_xn=tensor(-636.0931), f_x0=tensor(-636.3199), alpha=tensor(0.7528)\n",
      "Accepting with params: f_xn=tensor(-635.9334), f_x0=tensor(-636.0931), alpha=tensor(0.7039)\n",
      "Accepting with params: f_xn=tensor(-637.5940), f_x0=tensor(-635.9334), alpha=tensor(0.1140)\n",
      "Accepting with params: f_xn=tensor(-635.2031), f_x0=tensor(-637.5940), alpha=tensor(6.5538)\n",
      "Accepting with params: f_xn=tensor(-634.7341), f_x0=tensor(-635.2031), alpha=tensor(0.9591)\n",
      "Accepting with params: f_xn=tensor(-635.5383), f_x0=tensor(-634.7341), alpha=tensor(0.2685)\n",
      "Accepting with params: f_xn=tensor(-634.7690), f_x0=tensor(-635.5383), alpha=tensor(1.2950)\n",
      "Accepting with params: f_xn=tensor(-639.0866), f_x0=tensor(-634.7690), alpha=tensor(0.0080)\n",
      "Accepting with params: f_xn=tensor(-635.0497), f_x0=tensor(-639.0866), alpha=tensor(33.9891)\n",
      "Accepting with params: f_xn=tensor(-634.3872), f_x0=tensor(-635.0497), alpha=tensor(1.1638)\n",
      "Accepting with params: f_xn=tensor(-634.0948), f_x0=tensor(-634.3872), alpha=tensor(0.8038)\n",
      "Accepting with params: f_xn=tensor(-635.2748), f_x0=tensor(-634.0948), alpha=tensor(0.1844)\n",
      "Accepting with params: f_xn=tensor(-634.0202), f_x0=tensor(-635.2748), alpha=tensor(2.1038)\n",
      "Accepting with params: f_xn=tensor(-634.7289), f_x0=tensor(-634.0202), alpha=tensor(0.2954)\n",
      "Accepting with params: f_xn=tensor(-634.2673), f_x0=tensor(-634.7289), alpha=tensor(0.9520)\n",
      "Accepting with params: f_xn=tensor(-634.3519), f_x0=tensor(-634.2673), alpha=tensor(0.5513)\n",
      "Accepting with params: f_xn=tensor(-634.8129), f_x0=tensor(-634.3519), alpha=tensor(0.3784)\n",
      "Accepting with params: f_xn=tensor(-634.8116), f_x0=tensor(-634.8129), alpha=tensor(0.6007)\n",
      "Accepting with params: f_xn=tensor(-634.5128), f_x0=tensor(-634.8116), alpha=tensor(0.8090)\n",
      "Accepting with params: f_xn=tensor(-633.9517), f_x0=tensor(-634.5128), alpha=tensor(1.0516)\n",
      "Accepting with params: f_xn=tensor(-635.1786), f_x0=tensor(-633.9517), alpha=tensor(0.1759)\n",
      "Accepting with params: f_xn=tensor(-634.7901), f_x0=tensor(-635.1786), alpha=tensor(0.8849)\n",
      "Accepting with params: f_xn=tensor(-634.5383), f_x0=tensor(-634.7901), alpha=tensor(0.7718)\n",
      "Accepting with params: f_xn=tensor(-634.8118), f_x0=tensor(-634.5383), alpha=tensor(0.4564)\n",
      "Accepting with params: f_xn=tensor(-635.6384), f_x0=tensor(-634.8118), alpha=tensor(0.2625)\n",
      "Accepting with params: f_xn=tensor(-635.6699), f_x0=tensor(-635.6384), alpha=tensor(0.5814)\n",
      "Accepting with params: f_xn=tensor(-635.1108), f_x0=tensor(-635.6699), alpha=tensor(1.0494)\n",
      "Accepting with params: f_xn=tensor(-635.3036), f_x0=tensor(-635.1108), alpha=tensor(0.4948)\n",
      "Accepting with params: f_xn=tensor(-634.9053), f_x0=tensor(-635.3036), alpha=tensor(0.8935)\n",
      "Accepting with params: f_xn=tensor(-635.4952), f_x0=tensor(-634.9053), alpha=tensor(0.3326)\n",
      "Accepting with params: f_xn=tensor(-635.5212), f_x0=tensor(-635.4952), alpha=tensor(0.5846)\n",
      "Accepting with params: f_xn=tensor(-635.3068), f_x0=tensor(-635.5212), alpha=tensor(0.7435)\n",
      "Accepting with params: f_xn=tensor(-635.7505), f_x0=tensor(-635.3068), alpha=tensor(0.3850)\n",
      "Accepting with params: f_xn=tensor(-635.7196), f_x0=tensor(-635.7505), alpha=tensor(0.6189)\n",
      "Accepting with params: f_xn=tensor(-635.4158), f_x0=tensor(-635.7196), alpha=tensor(0.8130)\n",
      "Accepting with params: f_xn=tensor(-635.1383), f_x0=tensor(-635.4158), alpha=tensor(0.7919)\n",
      "Accepting with params: f_xn=tensor(-636.2915), f_x0=tensor(-635.1383), alpha=tensor(0.1894)\n",
      "Accepting with params: f_xn=tensor(-635.6497), f_x0=tensor(-636.2915), alpha=tensor(1.1399)\n",
      "Accepting with params: f_xn=tensor(-635.3776), f_x0=tensor(-635.6497), alpha=tensor(0.7876)\n",
      "Accepting with params: f_xn=tensor(-636.4363), f_x0=tensor(-635.3776), alpha=tensor(0.2081)\n",
      "Accepting with params: f_xn=tensor(-634.8457), f_x0=tensor(-636.4363), alpha=tensor(2.9441)\n",
      "Accepting with params: f_xn=tensor(-634.7169), f_x0=tensor(-634.8457), alpha=tensor(0.6825)\n",
      "Accepting with params: f_xn=tensor(-633.8152), f_x0=tensor(-634.7169), alpha=tensor(1.4781)\n",
      "Accepting with params: f_xn=tensor(-633.8043), f_x0=tensor(-633.8152), alpha=tensor(0.6066)\n",
      "Accepting with params: f_xn=tensor(-633.1005), f_x0=tensor(-633.8043), alpha=tensor(1.2128)\n",
      "Accepting with params: f_xn=tensor(-633.1197), f_x0=tensor(-633.1005), alpha=tensor(0.5886)\n",
      "Accepting with params: f_xn=tensor(-634.9546), f_x0=tensor(-633.1197), alpha=tensor(0.0958)\n",
      "Accepting with params: f_xn=tensor(-633.9577), f_x0=tensor(-634.9546), alpha=tensor(1.6259)\n",
      "Accepting with params: f_xn=tensor(-634.2623), f_x0=tensor(-633.9577), alpha=tensor(0.4424)\n",
      "Accepting with params: f_xn=tensor(-633.5529), f_x0=tensor(-634.2623), alpha=tensor(1.2198)\n",
      "Accepting with params: f_xn=tensor(-633.3681), f_x0=tensor(-633.5529), alpha=tensor(0.7218)\n",
      "Accepting with params: f_xn=tensor(-634.2655), f_x0=tensor(-633.3681), alpha=tensor(0.2446)\n",
      "Accepting with params: f_xn=tensor(-634.0152), f_x0=tensor(-634.2655), alpha=tensor(0.7707)\n",
      "Accepting with params: f_xn=tensor(-633.4208), f_x0=tensor(-634.0152), alpha=tensor(1.0871)\n",
      "Accepting with params: f_xn=tensor(-632.7863), f_x0=tensor(-633.4208), alpha=tensor(1.1317)\n",
      "Accepting with params: f_xn=tensor(-633.1432), f_x0=tensor(-632.7863), alpha=tensor(0.4199)\n",
      "Accepting with params: f_xn=tensor(-633.2727), f_x0=tensor(-633.1432), alpha=tensor(0.5271)\n",
      "Accepting with params: f_xn=tensor(-632.9565), f_x0=tensor(-633.2727), alpha=tensor(0.8232)\n",
      "Accepting with params: f_xn=tensor(-633.2050), f_x0=tensor(-632.9565), alpha=tensor(0.4680)\n",
      "Accepting with params: f_xn=tensor(-632.6271), f_x0=tensor(-633.2050), alpha=tensor(1.0694)\n",
      "Accepting with params: f_xn=tensor(-632.2614), f_x0=tensor(-632.6271), alpha=tensor(0.8649)\n",
      "Accepting with params: f_xn=tensor(-632.4031), f_x0=tensor(-632.2614), alpha=tensor(0.5207)\n",
      "Accepting with params: f_xn=tensor(-631.8935), f_x0=tensor(-632.4031), alpha=tensor(0.9988)\n",
      "Accepting with params: f_xn=tensor(-633.5856), f_x0=tensor(-631.8935), alpha=tensor(0.1105)\n",
      "Accepting with params: f_xn=tensor(-632.1436), f_x0=tensor(-633.5856), alpha=tensor(2.5374)\n",
      "Accepting with params: f_xn=tensor(-632.2797), f_x0=tensor(-632.1436), alpha=tensor(0.5236)\n",
      "Accepting with params: f_xn=tensor(-632.3495), f_x0=tensor(-632.2797), alpha=tensor(0.5595)\n",
      "Accepting with params: f_xn=tensor(-632.0273), f_x0=tensor(-632.3495), alpha=tensor(0.8281)\n",
      "Accepting with params: f_xn=tensor(-632.3240), f_x0=tensor(-632.0273), alpha=tensor(0.4460)\n",
      "Accepting with params: f_xn=tensor(-632.8763), f_x0=tensor(-632.3240), alpha=tensor(0.3454)\n",
      "Accepting with params: f_xn=tensor(-632.3814), f_x0=tensor(-632.8763), alpha=tensor(0.9842)\n",
      "Accepting with params: f_xn=tensor(-633.6642), f_x0=tensor(-632.3814), alpha=tensor(0.1664)\n",
      "Accepting with params: f_xn=tensor(-632.5683), f_x0=tensor(-633.6642), alpha=tensor(1.7951)\n",
      "Accepting with params: f_xn=tensor(-632.5380), f_x0=tensor(-632.5683), alpha=tensor(0.6185)\n",
      "Accepting with params: f_xn=tensor(-633.9438), f_x0=tensor(-632.5380), alpha=tensor(0.1471)\n",
      "Accepting with params: f_xn=tensor(-633.9601), f_x0=tensor(-633.9438), alpha=tensor(0.5903)\n",
      "Accepting with params: f_xn=tensor(-633.5921), f_x0=tensor(-633.9601), alpha=tensor(0.8669)\n",
      "Accepting with params: f_xn=tensor(-632.7081), f_x0=tensor(-633.5921), alpha=tensor(1.4524)\n",
      "Accepting with params: f_xn=tensor(-632.9816), f_x0=tensor(-632.7081), alpha=tensor(0.4564)\n",
      "Accepting with params: f_xn=tensor(-632.5953), f_x0=tensor(-632.9816), alpha=tensor(0.8830)\n",
      "Accepting with params: f_xn=tensor(-632.5934), f_x0=tensor(-632.5953), alpha=tensor(0.6011)\n",
      "Accepting with params: f_xn=tensor(-633.4810), f_x0=tensor(-632.5934), alpha=tensor(0.2470)\n",
      "Accepting with params: f_xn=tensor(-635.4432), f_x0=tensor(-633.4810), alpha=tensor(0.0843)\n",
      "Accepting with params: f_xn=tensor(-633.0408), f_x0=tensor(-635.4432), alpha=tensor(6.6298)\n",
      "Accepting with params: f_xn=tensor(-632.7244), f_x0=tensor(-633.0408), alpha=tensor(0.8234)\n",
      "Accepting with params: f_xn=tensor(-633.0223), f_x0=tensor(-632.7244), alpha=tensor(0.4454)\n",
      "Accepting with params: f_xn=tensor(-633.1692), f_x0=tensor(-633.0223), alpha=tensor(0.5180)\n",
      "Accepting with params: f_xn=tensor(-632.5597), f_x0=tensor(-633.1692), alpha=tensor(1.1037)\n",
      "Accepting with params: f_xn=tensor(-632.6880), f_x0=tensor(-632.5597), alpha=tensor(0.5278)\n",
      "Accepting with params: f_xn=tensor(-635.0245), f_x0=tensor(-632.6880), alpha=tensor(0.0580)\n",
      "Accepting with params: f_xn=tensor(-633.4750), f_x0=tensor(-635.0245), alpha=tensor(2.8256)\n",
      "Accepting with params: f_xn=tensor(-633.5815), f_x0=tensor(-633.4750), alpha=tensor(0.5394)\n",
      "Accepting with params: f_xn=tensor(-633.6367), f_x0=tensor(-633.5815), alpha=tensor(0.5678)\n",
      "Accepting with params: f_xn=tensor(-633.5080), f_x0=tensor(-633.6367), alpha=tensor(0.6824)\n",
      "Accepting with params: f_xn=tensor(-633.3008), f_x0=tensor(-633.5080), alpha=tensor(0.7381)\n",
      "Accepting with params: f_xn=tensor(-633.9057), f_x0=tensor(-633.3008), alpha=tensor(0.3277)\n",
      "Accepting with params: f_xn=tensor(-633.6826), f_x0=tensor(-633.9057), alpha=tensor(0.7500)\n",
      "Accepting with params: f_xn=tensor(-633.6198), f_x0=tensor(-633.6826), alpha=tensor(0.6389)\n",
      "Accepting with params: f_xn=tensor(-633.5135), f_x0=tensor(-633.6198), alpha=tensor(0.6672)\n",
      "Accepting with params: f_xn=tensor(-634.6678), f_x0=tensor(-633.5135), alpha=tensor(0.1892)\n",
      "Accepting with params: f_xn=tensor(-633.8080), f_x0=tensor(-634.6678), alpha=tensor(1.4177)\n",
      "Accepting with params: f_xn=tensor(-634.9073), f_x0=tensor(-633.8080), alpha=tensor(0.1999)\n",
      "Accepting with params: f_xn=tensor(-632.7648), f_x0=tensor(-634.9073), alpha=tensor(5.1122)\n",
      "Accepting with params: f_xn=tensor(-634.2247), f_x0=tensor(-632.7648), alpha=tensor(0.1394)\n",
      "Accepting with params: f_xn=tensor(-633.3063), f_x0=tensor(-634.2247), alpha=tensor(1.5032)\n",
      "Accepting with params: f_xn=tensor(-633.6154), f_x0=tensor(-633.3063), alpha=tensor(0.4405)\n",
      "Accepting with params: f_xn=tensor(-634.8429), f_x0=tensor(-633.6154), alpha=tensor(0.1758)\n",
      "Accepting with params: f_xn=tensor(-634.2941), f_x0=tensor(-634.8429), alpha=tensor(1.0387)\n",
      "Accepting with params: f_xn=tensor(-633.8631), f_x0=tensor(-634.2941), alpha=tensor(0.9232)\n",
      "Accepting with params: f_xn=tensor(-635.1814), f_x0=tensor(-633.8631), alpha=tensor(0.1606)\n",
      "Accepting with params: f_xn=tensor(-633.6854), f_x0=tensor(-635.1814), alpha=tensor(2.6782)\n",
      "Accepting with params: f_xn=tensor(-634.0197), f_x0=tensor(-633.6854), alpha=tensor(0.4295)\n",
      "Accepting with params: f_xn=tensor(-633.2277), f_x0=tensor(-634.0197), alpha=tensor(1.3247)\n",
      "Accepting with params: f_xn=tensor(-633.4263), f_x0=tensor(-633.2277), alpha=tensor(0.4919)\n",
      "Accepting with params: f_xn=tensor(-633.9354), f_x0=tensor(-633.4263), alpha=tensor(0.3606)\n",
      "Accepting with params: f_xn=tensor(-634.1349), f_x0=tensor(-633.9354), alpha=tensor(0.4915)\n",
      "Accepting with params: f_xn=tensor(-635.3732), f_x0=tensor(-634.1349), alpha=tensor(0.1739)\n",
      "Accepting with params: f_xn=tensor(-634.2426), f_x0=tensor(-635.3732), alpha=tensor(1.8585)\n",
      "Accepting with params: f_xn=tensor(-634.2592), f_x0=tensor(-634.2426), alpha=tensor(0.5901)\n",
      "Accepting with params: f_xn=tensor(-635.0492), f_x0=tensor(-634.2592), alpha=tensor(0.2723)\n",
      "Accepting with params: f_xn=tensor(-633.8196), f_x0=tensor(-635.0492), alpha=tensor(2.0519)\n",
      "Accepting with params: f_xn=tensor(-632.9474), f_x0=tensor(-633.8196), alpha=tensor(1.4352)\n",
      "Accepting with params: f_xn=tensor(-633.0968), f_x0=tensor(-632.9474), alpha=tensor(0.5168)\n",
      "Accepting with params: f_xn=tensor(-633.9699), f_x0=tensor(-633.0968), alpha=tensor(0.2506)\n",
      "Accepting with params: f_xn=tensor(-632.9344), f_x0=tensor(-633.9699), alpha=tensor(1.6898)\n",
      "Accepting with params: f_xn=tensor(-633.2810), f_x0=tensor(-632.9344), alpha=tensor(0.4243)\n",
      "Accepting with params: f_xn=tensor(-633.4115), f_x0=tensor(-633.2810), alpha=tensor(0.5266)\n",
      "Accepting with params: f_xn=tensor(-632.9819), f_x0=tensor(-633.4115), alpha=tensor(0.9220)\n",
      "Accepting with params: f_xn=tensor(-633.0950), f_x0=tensor(-632.9819), alpha=tensor(0.5358)\n",
      "Accepting with params: f_xn=tensor(-633.0344), f_x0=tensor(-633.0950), alpha=tensor(0.6375)\n",
      "Accepting with params: f_xn=tensor(-632.9538), f_x0=tensor(-633.0344), alpha=tensor(0.6503)\n",
      "Accepting with params: f_xn=tensor(-633.1918), f_x0=tensor(-632.9538), alpha=tensor(0.4729)\n",
      "Accepting with params: f_xn=tensor(-633.7441), f_x0=tensor(-633.1918), alpha=tensor(0.3454)\n",
      "Accepting with params: f_xn=tensor(-633.0416), f_x0=tensor(-633.7441), alpha=tensor(1.2113)\n",
      "Accepting with params: f_xn=tensor(-632.9092), f_x0=tensor(-633.0416), alpha=tensor(0.6849)\n",
      "Accepting with params: f_xn=tensor(-633.2131), f_x0=tensor(-632.9092), alpha=tensor(0.4428)\n",
      "Accepting with params: f_xn=tensor(-633.0389), f_x0=tensor(-633.2131), alpha=tensor(0.7142)\n",
      "Accepting with params: f_xn=tensor(-634.0259), f_x0=tensor(-633.0389), alpha=tensor(0.2236)\n",
      "Accepting with params: f_xn=tensor(-632.7124), f_x0=tensor(-634.0259), alpha=tensor(2.2316)\n",
      "Accepting with params: f_xn=tensor(-635.0186), f_x0=tensor(-632.7124), alpha=tensor(0.0598)\n",
      "Accepting with params: f_xn=tensor(-633.2643), f_x0=tensor(-635.0186), alpha=tensor(3.4678)\n",
      "Accepting with params: f_xn=tensor(-634.7070), f_x0=tensor(-633.2643), alpha=tensor(0.1418)\n",
      "Accepting with params: f_xn=tensor(-634.6411), f_x0=tensor(-634.7070), alpha=tensor(0.6409)\n",
      "Accepting with params: f_xn=tensor(-633.8095), f_x0=tensor(-634.6411), alpha=tensor(1.3781)\n",
      "Accepting with params: f_xn=tensor(-633.6141), f_x0=tensor(-633.8095), alpha=tensor(0.7295)\n",
      "Accepting with params: f_xn=tensor(-633.5893), f_x0=tensor(-633.6141), alpha=tensor(0.6151)\n",
      "Accepting with params: f_xn=tensor(-633.5111), f_x0=tensor(-633.5893), alpha=tensor(0.6488)\n",
      "Accepting with params: f_xn=tensor(-633.1545), f_x0=tensor(-633.5111), alpha=tensor(0.8571)\n",
      "Accepting with params: f_xn=tensor(-633.4023), f_x0=tensor(-633.1545), alpha=tensor(0.4683)\n",
      "Accepting with params: f_xn=tensor(-634.0690), f_x0=tensor(-633.4023), alpha=tensor(0.3081)\n",
      "Accepting with params: f_xn=tensor(-633.9628), f_x0=tensor(-634.0690), alpha=tensor(0.6672)\n",
      "Accepting with params: f_xn=tensor(-635.6801), f_x0=tensor(-633.9628), alpha=tensor(0.1077)\n",
      "Accepting with params: f_xn=tensor(-634.1793), f_x0=tensor(-635.6801), alpha=tensor(2.6913)\n",
      "Accepting with params: f_xn=tensor(-633.9865), f_x0=tensor(-634.1793), alpha=tensor(0.7275)\n",
      "Accepting with params: f_xn=tensor(-634.5643), f_x0=tensor(-633.9865), alpha=tensor(0.3367)\n",
      "Accepting with params: f_xn=tensor(-634.7468), f_x0=tensor(-634.5643), alpha=tensor(0.4999)\n",
      "Accepting with params: f_xn=tensor(-635.1041), f_x0=tensor(-634.7468), alpha=tensor(0.4197)\n",
      "Accepting with params: f_xn=tensor(-634.8728), f_x0=tensor(-635.1041), alpha=tensor(0.7562)\n",
      "Accepting with params: f_xn=tensor(-634.0614), f_x0=tensor(-634.8728), alpha=tensor(1.3506)\n",
      "Accepting with params: f_xn=tensor(-636.3036), f_x0=tensor(-634.0614), alpha=tensor(0.0637)\n",
      "Accepting with params: f_xn=tensor(-635.2291), f_x0=tensor(-636.3036), alpha=tensor(1.7571)\n",
      "Accepting with params: f_xn=tensor(-635.6534), f_x0=tensor(-635.2291), alpha=tensor(0.3926)\n",
      "Accepting with params: f_xn=tensor(-636.8329), f_x0=tensor(-635.6534), alpha=tensor(0.1844)\n",
      "Accepting with params: f_xn=tensor(-636.3683), f_x0=tensor(-636.8329), alpha=tensor(0.9549)\n",
      "Accepting with params: f_xn=tensor(-636.5782), f_x0=tensor(-636.3683), alpha=tensor(0.4864)\n",
      "Accepting with params: f_xn=tensor(-634.8804), f_x0=tensor(-636.5782), alpha=tensor(3.2770)\n",
      "Accepting with params: f_xn=tensor(-634.9202), f_x0=tensor(-634.8804), alpha=tensor(0.5766)\n",
      "Accepting with params: f_xn=tensor(-634.9728), f_x0=tensor(-634.9202), alpha=tensor(0.5692)\n",
      "Accepting with params: f_xn=tensor(-634.7218), f_x0=tensor(-634.9728), alpha=tensor(0.7712)\n",
      "Accepting with params: f_xn=tensor(-635.9944), f_x0=tensor(-634.7218), alpha=tensor(0.1681)\n",
      "Accepting with params: f_xn=tensor(-635.1696), f_x0=tensor(-635.9944), alpha=tensor(1.3690)\n",
      "Accepting with params: f_xn=tensor(-634.9974), f_x0=tensor(-635.1696), alpha=tensor(0.7127)\n",
      "Accepting with params: f_xn=tensor(-635.9535), f_x0=tensor(-634.9974), alpha=tensor(0.2306)\n",
      "Accepting with params: f_xn=tensor(-635.4917), f_x0=tensor(-635.9535), alpha=tensor(0.9521)\n",
      "Accepting with params: f_xn=tensor(-635.4676), f_x0=tensor(-635.4917), alpha=tensor(0.6146)\n",
      "Accepting with params: f_xn=tensor(-636.2827), f_x0=tensor(-635.4676), alpha=tensor(0.2656)\n",
      "Accepting with params: f_xn=tensor(-638.1972), f_x0=tensor(-636.2827), alpha=tensor(0.0884)\n",
      "Accepting with params: f_xn=tensor(-636.4469), f_x0=tensor(-638.1972), alpha=tensor(3.4538)\n",
      "Accepting with params: f_xn=tensor(-635.9030), f_x0=tensor(-636.4469), alpha=tensor(1.0337)\n",
      "Accepting with params: f_xn=tensor(-636.7424), f_x0=tensor(-635.9030), alpha=tensor(0.2592)\n",
      "Accepting with params: f_xn=tensor(-635.7305), f_x0=tensor(-636.7424), alpha=tensor(1.6505)\n",
      "Accepting with params: f_xn=tensor(-636.8708), f_x0=tensor(-635.7305), alpha=tensor(0.1918)\n",
      "Accepting with params: f_xn=tensor(-635.7936), f_x0=tensor(-636.8708), alpha=tensor(1.7618)\n",
      "Accepting with params: f_xn=tensor(-635.1195), f_x0=tensor(-635.7936), alpha=tensor(1.1774)\n",
      "Accepting with params: f_xn=tensor(-635.7631), f_x0=tensor(-635.1195), alpha=tensor(0.3153)\n",
      "Accepting with params: f_xn=tensor(-635.4712), f_x0=tensor(-635.7631), alpha=tensor(0.8034)\n",
      "Accepting with params: f_xn=tensor(-635.9142), f_x0=tensor(-635.4712), alpha=tensor(0.3853)\n",
      "Accepting with params: f_xn=tensor(-635.8966), f_x0=tensor(-635.9142), alpha=tensor(0.6106)\n",
      "Accepting with params: f_xn=tensor(-635.4972), f_x0=tensor(-635.8966), alpha=tensor(0.8946)\n",
      "Accepting with params: f_xn=tensor(-636.9960), f_x0=tensor(-635.4972), alpha=tensor(0.1340)\n",
      "Accepting with params: f_xn=tensor(-638.9451), f_x0=tensor(-636.9960), alpha=tensor(0.0854)\n",
      "Accepting with params: f_xn=tensor(-635.2299), f_x0=tensor(-638.9451), alpha=tensor(24.6388)\n",
      "Accepting with params: f_xn=tensor(-635.8654), f_x0=tensor(-635.2299), alpha=tensor(0.3178)\n",
      "Accepting with params: f_xn=tensor(-635.1051), f_x0=tensor(-635.8654), alpha=tensor(1.2833)\n",
      "Accepting with params: f_xn=tensor(-634.3922), f_x0=tensor(-635.1051), alpha=tensor(1.2239)\n",
      "Accepting with params: f_xn=tensor(-634.6142), f_x0=tensor(-634.3922), alpha=tensor(0.4806)\n",
      "Accepting with params: f_xn=tensor(-635.7411), f_x0=tensor(-634.6142), alpha=tensor(0.1944)\n",
      "Accepting with params: f_xn=tensor(-635.1809), f_x0=tensor(-635.7411), alpha=tensor(1.0507)\n",
      "Accepting with params: f_xn=tensor(-635.3803), f_x0=tensor(-635.1809), alpha=tensor(0.4915)\n",
      "Accepting with params: f_xn=tensor(-635.9990), f_x0=tensor(-635.3803), alpha=tensor(0.3232)\n",
      "Accepting with params: f_xn=tensor(-635.8687), f_x0=tensor(-635.9990), alpha=tensor(0.6835)\n",
      "Accepting with params: f_xn=tensor(-635.4052), f_x0=tensor(-635.8687), alpha=tensor(0.9538)\n",
      "Accepting with params: f_xn=tensor(-635.6203), f_x0=tensor(-635.4052), alpha=tensor(0.4839)\n",
      "Accepting with params: f_xn=tensor(-635.5701), f_x0=tensor(-635.6203), alpha=tensor(0.6309)\n",
      "Accepting with params: f_xn=tensor(-634.9648), f_x0=tensor(-635.5701), alpha=tensor(1.0991)\n",
      "Accepting with params: f_xn=tensor(-635.8200), f_x0=tensor(-634.9648), alpha=tensor(0.2551)\n",
      "Accepting with params: f_xn=tensor(-635.0253), f_x0=tensor(-635.8200), alpha=tensor(1.3283)\n",
      "Accepting with params: f_xn=tensor(-634.4050), f_x0=tensor(-635.0253), alpha=tensor(1.1156)\n",
      "Accepting with params: f_xn=tensor(-635.3825), f_x0=tensor(-634.4050), alpha=tensor(0.2258)\n",
      "Accepting with params: f_xn=tensor(-633.5967), f_x0=tensor(-635.3825), alpha=tensor(3.5787)\n",
      "Accepting with params: f_xn=tensor(-634.7361), f_x0=tensor(-633.5967), alpha=tensor(0.1920)\n",
      "Accepting with params: f_xn=tensor(-634.0314), f_x0=tensor(-634.7361), alpha=tensor(1.2140)\n",
      "Accepting with params: f_xn=tensor(-634.0533), f_x0=tensor(-634.0314), alpha=tensor(0.5870)\n",
      "Accepting with params: f_xn=tensor(-634.2094), f_x0=tensor(-634.0533), alpha=tensor(0.5133)\n",
      "Accepting with params: f_xn=tensor(-634.5982), f_x0=tensor(-634.2094), alpha=tensor(0.4067)\n",
      "Accepting with params: f_xn=tensor(-635.4841), f_x0=tensor(-634.5982), alpha=tensor(0.2474)\n",
      "Accepting with params: f_xn=tensor(-634.9919), f_x0=tensor(-635.4841), alpha=tensor(0.9816)\n",
      "Accepting with params: f_xn=tensor(-635.0204), f_x0=tensor(-634.9919), alpha=tensor(0.5831)\n",
      "Accepting with params: f_xn=tensor(-634.3705), f_x0=tensor(-635.0204), alpha=tensor(1.1493)\n",
      "Accepting with params: f_xn=tensor(-634.1466), f_x0=tensor(-634.3705), alpha=tensor(0.7506)\n",
      "Accepting with params: f_xn=tensor(-633.9672), f_x0=tensor(-634.1466), alpha=tensor(0.7179)\n",
      "Accepting with params: f_xn=tensor(-633.4305), f_x0=tensor(-633.9672), alpha=tensor(1.0262)\n",
      "Accepting with params: f_xn=tensor(-633.4780), f_x0=tensor(-633.4305), alpha=tensor(0.5722)\n",
      "Accepting with params: f_xn=tensor(-633.5356), f_x0=tensor(-633.4780), alpha=tensor(0.5664)\n",
      "Accepting with params: f_xn=tensor(-633.0710), f_x0=tensor(-633.5356), alpha=tensor(0.9548)\n",
      "Accepting with params: f_xn=tensor(-633.0940), f_x0=tensor(-633.0710), alpha=tensor(0.5864)\n",
      "Accepting with params: f_xn=tensor(-633.5979), f_x0=tensor(-633.0940), alpha=tensor(0.3625)\n",
      "Accepting with params: f_xn=tensor(-633.0096), f_x0=tensor(-633.5979), alpha=tensor(1.0806)\n",
      "Accepting with params: f_xn=tensor(-634.3970), f_x0=tensor(-633.0096), alpha=tensor(0.1498)\n",
      "Accepting with params: f_xn=tensor(-633.5798), f_x0=tensor(-634.3970), alpha=tensor(1.3585)\n",
      "Accepting with params: f_xn=tensor(-633.2393), f_x0=tensor(-633.5798), alpha=tensor(0.8435)\n",
      "Accepting with params: f_xn=tensor(-635.0379), f_x0=tensor(-633.2393), alpha=tensor(0.0993)\n",
      "Accepting with params: f_xn=tensor(-634.0118), f_x0=tensor(-635.0379), alpha=tensor(1.6740)\n",
      "Accepting with params: f_xn=tensor(-633.8502), f_x0=tensor(-634.0118), alpha=tensor(0.7053)\n",
      "Accepting with params: f_xn=tensor(-638.1456), f_x0=tensor(-633.8502), alpha=tensor(0.0082)\n",
      "Accepting with params: f_xn=tensor(-636.0912), f_x0=tensor(-638.1456), alpha=tensor(4.6809)\n",
      "Accepting with params: f_xn=tensor(-636.1870), f_x0=tensor(-636.0912), alpha=tensor(0.5452)\n",
      "Accepting with params: f_xn=tensor(-633.5307), f_x0=tensor(-636.1870), alpha=tensor(8.5462)\n",
      "Accepting with params: f_xn=tensor(-633.6844), f_x0=tensor(-633.5307), alpha=tensor(0.5145)\n",
      "Accepting with params: f_xn=tensor(-633.7994), f_x0=tensor(-633.6844), alpha=tensor(0.5349)\n",
      "Accepting with params: f_xn=tensor(-633.6831), f_x0=tensor(-633.7994), alpha=tensor(0.6740)\n",
      "Accepting with params: f_xn=tensor(-633.0171), f_x0=tensor(-633.6831), alpha=tensor(1.1679)\n",
      "Accepting with params: f_xn=tensor(-632.9529), f_x0=tensor(-633.0171), alpha=tensor(0.6398)\n",
      "Accepting with params: f_xn=tensor(-633.2183), f_x0=tensor(-632.9529), alpha=tensor(0.4602)\n",
      "Accepting with params: f_xn=tensor(-634.0443), f_x0=tensor(-633.2183), alpha=tensor(0.2627)\n",
      "Accepting with params: f_xn=tensor(-633.5674), f_x0=tensor(-634.0443), alpha=tensor(0.9667)\n",
      "Accepting with params: f_xn=tensor(-633.1749), f_x0=tensor(-633.5674), alpha=tensor(0.8884)\n",
      "Accepting with params: f_xn=tensor(-633.3899), f_x0=tensor(-633.1749), alpha=tensor(0.4839)\n",
      "Accepting with params: f_xn=tensor(-633.6231), f_x0=tensor(-633.3899), alpha=tensor(0.4752)\n",
      "Accepting with params: f_xn=tensor(-634.4241), f_x0=tensor(-633.6231), alpha=tensor(0.2693)\n",
      "Accepting with params: f_xn=tensor(-635.2251), f_x0=tensor(-634.4241), alpha=tensor(0.2693)\n",
      "Accepting with params: f_xn=tensor(-633.3530), f_x0=tensor(-635.2251), alpha=tensor(3.9010)\n",
      "Accepting with params: f_xn=tensor(-633.7577), f_x0=tensor(-633.3530), alpha=tensor(0.4003)\n",
      "Accepting with params: f_xn=tensor(-633.7499), f_x0=tensor(-633.7577), alpha=tensor(0.6047)\n",
      "Accepting with params: f_xn=tensor(-633.6774), f_x0=tensor(-633.7499), alpha=tensor(0.6451)\n",
      "Accepting with params: f_xn=tensor(-633.3857), f_x0=tensor(-633.6774), alpha=tensor(0.8032)\n",
      "Accepting with params: f_xn=tensor(-631.6647), f_x0=tensor(-633.3857), alpha=tensor(3.3539)\n",
      "Accepting with params: f_xn=tensor(-631.5570), f_x0=tensor(-631.6647), alpha=tensor(0.6682)\n",
      "Accepting with params: f_xn=tensor(-631.8621), f_x0=tensor(-631.5570), alpha=tensor(0.4422)\n",
      "Accepting with params: f_xn=tensor(-633.6965), f_x0=tensor(-631.8621), alpha=tensor(0.0958)\n",
      "Accepting with params: f_xn=tensor(-632.5601), f_x0=tensor(-633.6965), alpha=tensor(1.8692)\n",
      "Accepting with params: f_xn=tensor(-632.8042), f_x0=tensor(-632.5601), alpha=tensor(0.4701)\n",
      "Accepting with params: f_xn=tensor(-632.4196), f_x0=tensor(-632.8042), alpha=tensor(0.8815)\n",
      "Accepting with params: f_xn=tensor(-633.5797), f_x0=tensor(-632.4196), alpha=tensor(0.1881)\n",
      "Accepting with params: f_xn=tensor(-632.7396), f_x0=tensor(-633.5797), alpha=tensor(1.3899)\n",
      "Accepting with params: f_xn=tensor(-633.7536), f_x0=tensor(-632.7396), alpha=tensor(0.2177)\n",
      "Accepting with params: f_xn=tensor(-633.1362), f_x0=tensor(-633.7536), alpha=tensor(1.1125)\n",
      "Accepting with params: f_xn=tensor(-632.7872), f_x0=tensor(-633.1362), alpha=tensor(0.8506)\n",
      "Accepting with params: f_xn=tensor(-632.4934), f_x0=tensor(-632.7872), alpha=tensor(0.8049)\n",
      "Accepting with params: f_xn=tensor(-632.4276), f_x0=tensor(-632.4934), alpha=tensor(0.6408)\n",
      "Accepting with params: f_xn=tensor(-632.8239), f_x0=tensor(-632.4276), alpha=tensor(0.4037)\n",
      "Accepting with params: f_xn=tensor(-632.5674), f_x0=tensor(-632.8239), alpha=tensor(0.7754)\n",
      "Accepting with params: f_xn=tensor(-633.1649), f_x0=tensor(-632.5674), alpha=tensor(0.3301)\n",
      "Accepting with params: f_xn=tensor(-632.8171), f_x0=tensor(-633.1649), alpha=tensor(0.8495)\n",
      "Accepting with params: f_xn=tensor(-632.6968), f_x0=tensor(-632.8171), alpha=tensor(0.6767)\n",
      "Accepting with params: f_xn=tensor(-633.0500), f_x0=tensor(-632.6968), alpha=tensor(0.4214)\n",
      "Accepting with params: f_xn=tensor(-632.7713), f_x0=tensor(-633.0500), alpha=tensor(0.7929)\n",
      "Accepting with params: f_xn=tensor(-634.1171), f_x0=tensor(-632.7713), alpha=tensor(0.1562)\n",
      "Accepting with params: f_xn=tensor(-633.6664), f_x0=tensor(-634.1171), alpha=tensor(0.9416)\n",
      "Accepting with params: f_xn=tensor(-632.5527), f_x0=tensor(-633.6664), alpha=tensor(1.8274)\n",
      "Accepting with params: f_xn=tensor(-633.8995), f_x0=tensor(-632.5527), alpha=tensor(0.1561)\n",
      "Accepting with params: f_xn=tensor(-631.9851), f_x0=tensor(-633.8995), alpha=tensor(4.0696)\n",
      "Accepting with params: f_xn=tensor(-632.1458), f_x0=tensor(-631.9851), alpha=tensor(0.5110)\n",
      "Accepting with params: f_xn=tensor(-632.7810), f_x0=tensor(-632.1458), alpha=tensor(0.3179)\n",
      "Accepting with params: f_xn=tensor(-633.9897), f_x0=tensor(-632.7810), alpha=tensor(0.1792)\n",
      "Accepting with params: f_xn=tensor(-633.7660), f_x0=tensor(-633.9897), alpha=tensor(0.7504)\n",
      "Accepting with params: f_xn=tensor(-633.2975), f_x0=tensor(-633.7660), alpha=tensor(0.9586)\n",
      "Accepting with params: f_xn=tensor(-632.9470), f_x0=tensor(-633.2975), alpha=tensor(0.8518)\n",
      "Accepting with params: f_xn=tensor(-632.6147), f_x0=tensor(-632.9470), alpha=tensor(0.8365)\n",
      "Accepting with params: f_xn=tensor(-633.1014), f_x0=tensor(-632.6147), alpha=tensor(0.3688)\n",
      "Accepting with params: f_xn=tensor(-633.1037), f_x0=tensor(-633.1014), alpha=tensor(0.5986)\n",
      "Accepting with params: f_xn=tensor(-632.8140), f_x0=tensor(-633.1037), alpha=tensor(0.8016)\n",
      "Accepting with params: f_xn=tensor(-634.2621), f_x0=tensor(-632.8140), alpha=tensor(0.1410)\n",
      "Accepting with params: f_xn=tensor(-632.3638), f_x0=tensor(-634.2621), alpha=tensor(4.0050)\n",
      "Accepting with params: f_xn=tensor(-631.8413), f_x0=tensor(-632.3638), alpha=tensor(1.0117)\n",
      "Accepting with params: f_xn=tensor(-632.4377), f_x0=tensor(-631.8413), alpha=tensor(0.3305)\n",
      "Accepting with params: f_xn=tensor(-632.5783), f_x0=tensor(-632.4377), alpha=tensor(0.5213)\n",
      "Accepting with params: f_xn=tensor(-632.5510), f_x0=tensor(-632.5783), alpha=tensor(0.6166)\n",
      "Accepting with params: f_xn=tensor(-632.3071), f_x0=tensor(-632.5510), alpha=tensor(0.7657)\n",
      "Accepting with params: f_xn=tensor(-632.6777), f_x0=tensor(-632.3071), alpha=tensor(0.4142)\n",
      "Accepting with params: f_xn=tensor(-631.8488), f_x0=tensor(-632.6777), alpha=tensor(1.3744)\n",
      "Accepting with params: f_xn=tensor(-631.7457), f_x0=tensor(-631.8488), alpha=tensor(0.6652)\n",
      "Accepting with params: f_xn=tensor(-632.4439), f_x0=tensor(-631.7457), alpha=tensor(0.2985)\n",
      "Accepting with params: f_xn=tensor(-632.6292), f_x0=tensor(-632.4439), alpha=tensor(0.4985)\n",
      "Accepting with params: f_xn=tensor(-631.4026), f_x0=tensor(-632.6292), alpha=tensor(2.0456)\n",
      "Accepting with params: f_xn=tensor(-632.4848), f_x0=tensor(-631.4026), alpha=tensor(0.2033)\n",
      "Accepting with params: f_xn=tensor(-631.7466), f_x0=tensor(-632.4848), alpha=tensor(1.2552)\n",
      "Accepting with params: f_xn=tensor(-631.2148), f_x0=tensor(-631.7466), alpha=tensor(1.0212)\n",
      "Accepting with params: f_xn=tensor(-631.2062), f_x0=tensor(-631.2148), alpha=tensor(0.6052)\n",
      "Accepting with params: f_xn=tensor(-631.7890), f_x0=tensor(-631.2062), alpha=tensor(0.3350)\n",
      "Accepting with params: f_xn=tensor(-632.2560), f_x0=tensor(-631.7890), alpha=tensor(0.3761)\n",
      "Accepting with params: f_xn=tensor(-631.6053), f_x0=tensor(-632.2560), alpha=tensor(1.1502)\n",
      "Accepting with params: f_xn=tensor(-631.9675), f_x0=tensor(-631.6053), alpha=tensor(0.4177)\n",
      "Accepting with params: f_xn=tensor(-631.1312), f_x0=tensor(-631.9675), alpha=tensor(1.3846)\n",
      "Accepting with params: f_xn=tensor(-631.8596), f_x0=tensor(-631.1312), alpha=tensor(0.2896)\n",
      "Accepting with params: f_xn=tensor(-631.8193), f_x0=tensor(-631.8596), alpha=tensor(0.6247)\n",
      "Accepting with params: f_xn=tensor(-631.6223), f_x0=tensor(-631.8193), alpha=tensor(0.7307)\n",
      "Accepting with params: f_xn=tensor(-632.7237), f_x0=tensor(-631.6223), alpha=tensor(0.1994)\n",
      "Accepting with params: f_xn=tensor(-631.4169), f_x0=tensor(-632.7237), alpha=tensor(2.2165)\n",
      "Accepting with params: f_xn=tensor(-631.7614), f_x0=tensor(-631.4169), alpha=tensor(0.4252)\n",
      "Accepting with params: f_xn=tensor(-631.4580), f_x0=tensor(-631.7614), alpha=tensor(0.8127)\n",
      "Accepting with params: f_xn=tensor(-632.5450), f_x0=tensor(-631.4580), alpha=tensor(0.2023)\n",
      "Accepting with params: f_xn=tensor(-633.1273), f_x0=tensor(-632.5450), alpha=tensor(0.3352)\n",
      "Accepting with params: f_xn=tensor(-632.5908), f_x0=tensor(-633.1273), alpha=tensor(1.0260)\n",
      "Accepting with params: f_xn=tensor(-632.9554), f_x0=tensor(-632.5908), alpha=tensor(0.4167)\n",
      "Accepting with params: f_xn=tensor(-632.2088), f_x0=tensor(-632.9554), alpha=tensor(1.2659)\n",
      "Accepting with params: f_xn=tensor(-631.3931), f_x0=tensor(-632.2088), alpha=tensor(1.3565)\n",
      "Accepting with params: f_xn=tensor(-630.8403), f_x0=tensor(-631.3931), alpha=tensor(1.0428)\n",
      "Accepting with params: f_xn=tensor(-632.4450), f_x0=tensor(-630.8403), alpha=tensor(0.1206)\n",
      "Accepting with params: f_xn=tensor(-631.9806), f_x0=tensor(-632.4450), alpha=tensor(0.9547)\n",
      "Accepting with params: f_xn=tensor(-630.5423), f_x0=tensor(-631.9806), alpha=tensor(2.5281)\n",
      "Accepting with params: f_xn=tensor(-630.3683), f_x0=tensor(-630.5423), alpha=tensor(0.7140)\n",
      "Accepting with params: f_xn=tensor(-630.3704), f_x0=tensor(-630.3683), alpha=tensor(0.5988)\n",
      "Accepting with params: f_xn=tensor(-630.3973), f_x0=tensor(-630.3704), alpha=tensor(0.5841)\n",
      "Accepting with params: f_xn=tensor(-630.4810), f_x0=tensor(-630.3973), alpha=tensor(0.5518)\n",
      "Accepting with params: f_xn=tensor(-631.5128), f_x0=tensor(-630.4810), alpha=tensor(0.2138)\n",
      "Accepting with params: f_xn=tensor(-630.2780), f_x0=tensor(-631.5128), alpha=tensor(2.0626)\n",
      "Accepting with params: f_xn=tensor(-630.6543), f_x0=tensor(-630.2780), alpha=tensor(0.4118)\n",
      "Accepting with params: f_xn=tensor(-631.6064), f_x0=tensor(-630.6543), alpha=tensor(0.2315)\n",
      "Accepting with params: f_xn=tensor(-630.1249), f_x0=tensor(-631.6064), alpha=tensor(2.6397)\n",
      "Accepting with params: f_xn=tensor(-629.9345), f_x0=tensor(-630.1249), alpha=tensor(0.7259)\n",
      "Accepting with params: f_xn=tensor(-629.7265), f_x0=tensor(-629.9345), alpha=tensor(0.7387)\n",
      "Accepting with params: f_xn=tensor(-630.1774), f_x0=tensor(-629.7265), alpha=tensor(0.3822)\n",
      "Accepting with params: f_xn=tensor(-629.6385), f_x0=tensor(-630.1774), alpha=tensor(1.0285)\n",
      "Accepting with params: f_xn=tensor(-629.1742), f_x0=tensor(-629.6385), alpha=tensor(0.9545)\n",
      "Accepting with params: f_xn=tensor(-629.7025), f_x0=tensor(-629.1742), alpha=tensor(0.3538)\n",
      "Accepting with params: f_xn=tensor(-629.0587), f_x0=tensor(-629.7025), alpha=tensor(1.1421)\n",
      "Accepting with params: f_xn=tensor(-629.5460), f_x0=tensor(-629.0587), alpha=tensor(0.3686)\n",
      "Accepting with params: f_xn=tensor(-630.2405), f_x0=tensor(-629.5460), alpha=tensor(0.2996)\n",
      "Accepting with params: f_xn=tensor(-629.5390), f_x0=tensor(-630.2405), alpha=tensor(1.2100)\n",
      "Accepting with params: f_xn=tensor(-629.1689), f_x0=tensor(-629.5390), alpha=tensor(0.8687)\n",
      "Accepting with params: f_xn=tensor(-629.5506), f_x0=tensor(-629.1689), alpha=tensor(0.4096)\n",
      "Accepting with params: f_xn=tensor(-630.0506), f_x0=tensor(-629.5506), alpha=tensor(0.3639)\n",
      "Accepting with params: f_xn=tensor(-629.6309), f_x0=tensor(-630.0506), alpha=tensor(0.9129)\n",
      "Accepting with params: f_xn=tensor(-629.5525), f_x0=tensor(-629.6309), alpha=tensor(0.6490)\n",
      "Accepting with params: f_xn=tensor(-630.6910), f_x0=tensor(-629.5525), alpha=tensor(0.1922)\n",
      "Accepting with params: f_xn=tensor(-630.2454), f_x0=tensor(-630.6910), alpha=tensor(0.9369)\n",
      "Accepting with params: f_xn=tensor(-632.8583), f_x0=tensor(-630.2454), alpha=tensor(0.0440)\n",
      "Accepting with params: f_xn=tensor(-630.2929), f_x0=tensor(-632.8583), alpha=tensor(7.8037)\n",
      "Accepting with params: f_xn=tensor(-629.8545), f_x0=tensor(-630.2929), alpha=tensor(0.9301)\n",
      "Accepting with params: f_xn=tensor(-631.3560), f_x0=tensor(-629.8545), alpha=tensor(0.1337)\n",
      "Accepting with params: f_xn=tensor(-630.7869), f_x0=tensor(-631.3560), alpha=tensor(1.0601)\n",
      "Accepting with params: f_xn=tensor(-630.5090), f_x0=tensor(-630.7869), alpha=tensor(0.7922)\n",
      "Accepting with params: f_xn=tensor(-631.5863), f_x0=tensor(-630.5090), alpha=tensor(0.2043)\n",
      "Accepting with params: f_xn=tensor(-630.8751), f_x0=tensor(-631.5863), alpha=tensor(1.2219)\n",
      "Accepting with params: f_xn=tensor(-630.7669), f_x0=tensor(-630.8751), alpha=tensor(0.6685)\n",
      "Accepting with params: f_xn=tensor(-632.2086), f_x0=tensor(-630.7669), alpha=tensor(0.1419)\n",
      "Accepting with params: f_xn=tensor(-631.1851), f_x0=tensor(-632.2086), alpha=tensor(1.6699)\n",
      "Accepting with params: f_xn=tensor(-630.7475), f_x0=tensor(-631.1851), alpha=tensor(0.9294)\n",
      "Accepting with params: f_xn=tensor(-630.6418), f_x0=tensor(-630.7475), alpha=tensor(0.6669)\n",
      "Accepting with params: f_xn=tensor(-630.4190), f_x0=tensor(-630.6418), alpha=tensor(0.7498)\n",
      "Accepting with params: f_xn=tensor(-631.3625), f_x0=tensor(-630.4190), alpha=tensor(0.2336)\n",
      "Accepting with params: f_xn=tensor(-630.3894), f_x0=tensor(-631.3625), alpha=tensor(1.5877)\n",
      "Accepting with params: f_xn=tensor(-630.3962), f_x0=tensor(-630.3894), alpha=tensor(0.5959)\n",
      "Accepting with params: f_xn=tensor(-630.3849), f_x0=tensor(-630.3962), alpha=tensor(0.6068)\n",
      "Accepting with params: f_xn=tensor(-632.0856), f_x0=tensor(-630.3849), alpha=tensor(0.1095)\n",
      "Accepting with params: f_xn=tensor(-630.6450), f_x0=tensor(-632.0856), alpha=tensor(2.5340)\n",
      "Accepting with params: f_xn=tensor(-631.7787), f_x0=tensor(-630.6450), alpha=tensor(0.1931)\n",
      "Accepting with params: f_xn=tensor(-631.8212), f_x0=tensor(-631.7787), alpha=tensor(0.5750)\n",
      "Accepting with params: f_xn=tensor(-631.7762), f_x0=tensor(-631.8212), alpha=tensor(0.6276)\n",
      "Accepting with params: f_xn=tensor(-632.0429), f_x0=tensor(-631.7762), alpha=tensor(0.4595)\n",
      "Accepting with params: f_xn=tensor(-633.6616), f_x0=tensor(-632.0429), alpha=tensor(0.1189)\n",
      "Accepting with params: f_xn=tensor(-632.7401), f_x0=tensor(-633.6616), alpha=tensor(1.5079)\n",
      "Accepting with params: f_xn=tensor(-632.7910), f_x0=tensor(-632.7401), alpha=tensor(0.5702)\n",
      "Accepting with params: f_xn=tensor(-632.8779), f_x0=tensor(-632.7910), alpha=tensor(0.5501)\n",
      "Accepting with params: f_xn=tensor(-633.4698), f_x0=tensor(-632.8779), alpha=tensor(0.3319)\n",
      "Accepting with params: f_xn=tensor(-633.0611), f_x0=tensor(-633.4698), alpha=tensor(0.9030)\n",
      "Accepting with params: f_xn=tensor(-633.3550), f_x0=tensor(-633.0611), alpha=tensor(0.4472)\n",
      "Accepting with params: f_xn=tensor(-633.4780), f_x0=tensor(-633.3550), alpha=tensor(0.5306)\n",
      "Accepting with params: f_xn=tensor(-632.7483), f_x0=tensor(-633.4780), alpha=tensor(1.2446)\n",
      "Accepting with params: f_xn=tensor(-632.7979), f_x0=tensor(-632.7483), alpha=tensor(0.5710)\n",
      "Accepting with params: f_xn=tensor(-633.1645), f_x0=tensor(-632.7979), alpha=tensor(0.4159)\n",
      "Accepting with params: f_xn=tensor(-634.2128), f_x0=tensor(-633.1645), alpha=tensor(0.2103)\n",
      "Accepting with params: f_xn=tensor(-632.0143), f_x0=tensor(-634.2128), alpha=tensor(5.4065)\n",
      "Accepting with params: f_xn=tensor(-631.7468), f_x0=tensor(-632.0143), alpha=tensor(0.7841)\n",
      "Accepting with params: f_xn=tensor(-631.6178), f_x0=tensor(-631.7468), alpha=tensor(0.6826)\n",
      "Accepting with params: f_xn=tensor(-631.2328), f_x0=tensor(-631.6178), alpha=tensor(0.8817)\n",
      "Accepting with params: f_xn=tensor(-631.3388), f_x0=tensor(-631.2328), alpha=tensor(0.5397)\n",
      "Accepting with params: f_xn=tensor(-631.2941), f_x0=tensor(-631.3388), alpha=tensor(0.6274)\n",
      "Accepting with params: f_xn=tensor(-631.1503), f_x0=tensor(-631.2941), alpha=tensor(0.6928)\n",
      "Accepting with params: f_xn=tensor(-631.1889), f_x0=tensor(-631.1503), alpha=tensor(0.5773)\n",
      "Accepting with params: f_xn=tensor(-630.6416), f_x0=tensor(-631.1889), alpha=tensor(1.0372)\n",
      "Accepting with params: f_xn=tensor(-632.6178), f_x0=tensor(-630.6416), alpha=tensor(0.0832)\n",
      "Accepting with params: f_xn=tensor(-631.5820), f_x0=tensor(-632.6178), alpha=tensor(1.6904)\n",
      "Accepting with params: f_xn=tensor(-630.5611), f_x0=tensor(-631.5820), alpha=tensor(1.6655)\n",
      "Accepting with params: f_xn=tensor(-630.7849), f_x0=tensor(-630.5611), alpha=tensor(0.4797)\n",
      "Accepting with params: f_xn=tensor(-631.6782), f_x0=tensor(-630.7849), alpha=tensor(0.2456)\n",
      "Accepting with params: f_xn=tensor(-630.9058), f_x0=tensor(-631.6782), alpha=tensor(1.2990)\n",
      "Accepting with params: f_xn=tensor(-631.1503), f_x0=tensor(-630.9058), alpha=tensor(0.4698)\n",
      "Accepting with params: f_xn=tensor(-632.5161), f_x0=tensor(-631.1503), alpha=tensor(0.1531)\n",
      "Accepting with params: f_xn=tensor(-631.9032), f_x0=tensor(-632.5161), alpha=tensor(1.1075)\n",
      "Accepting with params: f_xn=tensor(-632.3276), f_x0=tensor(-631.9032), alpha=tensor(0.3925)\n",
      "Accepting with params: f_xn=tensor(-631.8909), f_x0=tensor(-632.3276), alpha=tensor(0.9286)\n",
      "Accepting with params: f_xn=tensor(-632.0933), f_x0=tensor(-631.8909), alpha=tensor(0.4901)\n",
      "Accepting with params: f_xn=tensor(-633.6761), f_x0=tensor(-632.0933), alpha=tensor(0.1232)\n",
      "Accepting with params: f_xn=tensor(-632.2115), f_x0=tensor(-633.6761), alpha=tensor(2.5956)\n",
      "Accepting with params: f_xn=tensor(-631.4677), f_x0=tensor(-632.2115), alpha=tensor(1.2624)\n",
      "Accepting with params: f_xn=tensor(-632.7182), f_x0=tensor(-631.4677), alpha=tensor(0.1718)\n",
      "Accepting with params: f_xn=tensor(-631.8239), f_x0=tensor(-632.7182), alpha=tensor(1.4674)\n",
      "Accepting with params: f_xn=tensor(-630.8443), f_x0=tensor(-631.8239), alpha=tensor(1.5981)\n",
      "Accepting with params: f_xn=tensor(-630.8842), f_x0=tensor(-630.8443), alpha=tensor(0.5766)\n",
      "Accepting with params: f_xn=tensor(-631.6685), f_x0=tensor(-630.8842), alpha=tensor(0.2738)\n",
      "Accepting with params: f_xn=tensor(-631.3817), f_x0=tensor(-631.6685), alpha=tensor(0.7993)\n",
      "Accepting with params: f_xn=tensor(-631.8411), f_x0=tensor(-631.3817), alpha=tensor(0.3790)\n",
      "Accepting with params: f_xn=tensor(-631.8583), f_x0=tensor(-631.8411), alpha=tensor(0.5898)\n",
      "Accepting with params: f_xn=tensor(-631.5489), f_x0=tensor(-631.8583), alpha=tensor(0.8176)\n",
      "Accepting with params: f_xn=tensor(-631.8469), f_x0=tensor(-631.5489), alpha=tensor(0.4454)\n",
      "Accepting with params: f_xn=tensor(-631.8324), f_x0=tensor(-631.8469), alpha=tensor(0.6087)\n",
      "Accepting with params: f_xn=tensor(-630.8517), f_x0=tensor(-631.8324), alpha=tensor(1.5997)\n",
      "Accepting with params: f_xn=tensor(-630.8621), f_x0=tensor(-630.8517), alpha=tensor(0.5938)\n",
      "Accepting with params: f_xn=tensor(-631.1276), f_x0=tensor(-630.8621), alpha=tensor(0.4601)\n",
      "Accepting with params: f_xn=tensor(-631.6140), f_x0=tensor(-631.1276), alpha=tensor(0.3689)\n",
      "Accepting with params: f_xn=tensor(-631.2543), f_x0=tensor(-631.6140), alpha=tensor(0.8597)\n",
      "Accepting with params: f_xn=tensor(-631.5254), f_x0=tensor(-631.2543), alpha=tensor(0.4575)\n",
      "Accepting with params: f_xn=tensor(-631.4086), f_x0=tensor(-631.5254), alpha=tensor(0.6744)\n",
      "Accepting with params: f_xn=tensor(-631.5475), f_x0=tensor(-631.4086), alpha=tensor(0.5222)\n",
      "Accepting with params: f_xn=tensor(-631.6879), f_x0=tensor(-631.5475), alpha=tensor(0.5214)\n",
      "Accepting with params: f_xn=tensor(-631.4539), f_x0=tensor(-631.6879), alpha=tensor(0.7582)\n",
      "Accepting with params: f_xn=tensor(-630.9998), f_x0=tensor(-631.4539), alpha=tensor(0.9449)\n",
      "Accepting with params: f_xn=tensor(-630.8931), f_x0=tensor(-630.9998), alpha=tensor(0.6675)\n",
      "Accepting with params: f_xn=tensor(-630.4104), f_x0=tensor(-630.8931), alpha=tensor(0.9723)\n",
      "Accepting with params: f_xn=tensor(-631.5423), f_x0=tensor(-630.4104), alpha=tensor(0.1935)\n",
      "Accepting with params: f_xn=tensor(-632.1700), f_x0=tensor(-631.5423), alpha=tensor(0.3203)\n",
      "Accepting with params: f_xn=tensor(-630.7248), f_x0=tensor(-632.1700), alpha=tensor(2.5458)\n",
      "Accepting with params: f_xn=tensor(-630.9380), f_x0=tensor(-630.7248), alpha=tensor(0.4848)\n",
      "Accepting with params: f_xn=tensor(-630.9923), f_x0=tensor(-630.9380), alpha=tensor(0.5683)\n",
      "Accepting with params: f_xn=tensor(-631.2759), f_x0=tensor(-630.9923), alpha=tensor(0.4518)\n",
      "Accepting with params: f_xn=tensor(-631.3792), f_x0=tensor(-631.2759), alpha=tensor(0.5411)\n",
      "Accepting with params: f_xn=tensor(-631.0335), f_x0=tensor(-631.3792), alpha=tensor(0.8478)\n",
      "Accepting with params: f_xn=tensor(-633.3655), f_x0=tensor(-631.0335), alpha=tensor(0.0583)\n",
      "Accepting with params: f_xn=tensor(-631.9879), f_x0=tensor(-633.3655), alpha=tensor(2.3793)\n",
      "Accepting with params: f_xn=tensor(-632.0831), f_x0=tensor(-631.9879), alpha=tensor(0.5455)\n",
      "Accepting with params: f_xn=tensor(-631.3809), f_x0=tensor(-632.0831), alpha=tensor(1.2109)\n",
      "Accepting with params: f_xn=tensor(-630.9706), f_x0=tensor(-631.3809), alpha=tensor(0.9043)\n",
      "Accepting with params: f_xn=tensor(-631.1946), f_x0=tensor(-630.9706), alpha=tensor(0.4796)\n",
      "Accepting with params: f_xn=tensor(-631.1815), f_x0=tensor(-631.1946), alpha=tensor(0.6079)\n",
      "Accepting with params: f_xn=tensor(-630.9612), f_x0=tensor(-631.1815), alpha=tensor(0.7479)\n",
      "Accepting with params: f_xn=tensor(-631.3652), f_x0=tensor(-630.9612), alpha=tensor(0.4006)\n",
      "Accepting with params: f_xn=tensor(-631.3117), f_x0=tensor(-631.3652), alpha=tensor(0.6330)\n",
      "Accepting with params: f_xn=tensor(-631.9678), f_x0=tensor(-631.3117), alpha=tensor(0.3113)\n",
      "Accepting with params: f_xn=tensor(-631.4714), f_x0=tensor(-631.9678), alpha=tensor(0.9857)\n",
      "Accepting with params: f_xn=tensor(-630.9221), f_x0=tensor(-631.4714), alpha=tensor(1.0392)\n",
      "Accepting with params: f_xn=tensor(-632.1964), f_x0=tensor(-630.9221), alpha=tensor(0.1678)\n",
      "Accepting with params: f_xn=tensor(-631.8424), f_x0=tensor(-632.1964), alpha=tensor(0.8548)\n",
      "Accepting with params: f_xn=tensor(-632.0887), f_x0=tensor(-631.8424), alpha=tensor(0.4690)\n",
      "Accepting with params: f_xn=tensor(-630.9637), f_x0=tensor(-632.0887), alpha=tensor(1.8480)\n",
      "Accepting with params: f_xn=tensor(-631.5405), f_x0=tensor(-630.9637), alpha=tensor(0.3370)\n",
      "Accepting with params: f_xn=tensor(-631.0190), f_x0=tensor(-631.5405), alpha=tensor(1.0107)\n",
      "Accepting with params: f_xn=tensor(-633.4893), f_x0=tensor(-631.0190), alpha=tensor(0.0507)\n",
      "Accepting with params: f_xn=tensor(-630.5739), f_x0=tensor(-633.4893), alpha=tensor(11.0745)\n",
      "Accepting with params: f_xn=tensor(-631.7429), f_x0=tensor(-630.5739), alpha=tensor(0.1864)\n",
      "Accepting with params: f_xn=tensor(-630.5588), f_x0=tensor(-631.7429), alpha=tensor(1.9607)\n",
      "Accepting with params: f_xn=tensor(-630.6605), f_x0=tensor(-630.5588), alpha=tensor(0.5420)\n",
      "Accepting with params: f_xn=tensor(-631.4232), f_x0=tensor(-630.6605), alpha=tensor(0.2798)\n",
      "Accepting with params: f_xn=tensor(-630.5551), f_x0=tensor(-631.4232), alpha=tensor(1.4294)\n",
      "Accepting with params: f_xn=tensor(-630.4604), f_x0=tensor(-630.5551), alpha=tensor(0.6596)\n",
      "Accepting with params: f_xn=tensor(-631.3657), f_x0=tensor(-630.4604), alpha=tensor(0.2427)\n",
      "Accepting with params: f_xn=tensor(-630.8662), f_x0=tensor(-631.3657), alpha=tensor(0.9887)\n",
      "Accepting with params: f_xn=tensor(-631.6713), f_x0=tensor(-630.8662), alpha=tensor(0.2682)\n",
      "Accepting with params: f_xn=tensor(-630.6481), f_x0=tensor(-631.6713), alpha=tensor(1.6692)\n",
      "Accepting with params: f_xn=tensor(-630.6085), f_x0=tensor(-630.6481), alpha=tensor(0.6242)\n",
      "Accepting with params: f_xn=tensor(-630.3828), f_x0=tensor(-630.6085), alpha=tensor(0.7520)\n",
      "Accepting with params: f_xn=tensor(-630.7863), f_x0=tensor(-630.3828), alpha=tensor(0.4008)\n",
      "Accepting with params: f_xn=tensor(-630.3801), f_x0=tensor(-630.7863), alpha=tensor(0.9007)\n",
      "Accepting with params: f_xn=tensor(-630.1209), f_x0=tensor(-630.3801), alpha=tensor(0.7775)\n",
      "Accepting with params: f_xn=tensor(-630.6749), f_x0=tensor(-630.1209), alpha=tensor(0.3448)\n",
      "Accepting with params: f_xn=tensor(-630.6970), f_x0=tensor(-630.6749), alpha=tensor(0.5869)\n",
      "Accepting with params: f_xn=tensor(-630.5547), f_x0=tensor(-630.6970), alpha=tensor(0.6917)\n",
      "Accepting with params: f_xn=tensor(-630.8854), f_x0=tensor(-630.5547), alpha=tensor(0.4311)\n",
      "Accepting with params: f_xn=tensor(-631.0128), f_x0=tensor(-630.8854), alpha=tensor(0.5283)\n",
      "Accepting with params: f_xn=tensor(-631.0783), f_x0=tensor(-631.0128), alpha=tensor(0.5619)\n",
      "Accepting with params: f_xn=tensor(-631.1461), f_x0=tensor(-631.0783), alpha=tensor(0.5607)\n",
      "Accepting with params: f_xn=tensor(-631.2491), f_x0=tensor(-631.1461), alpha=tensor(0.5413)\n",
      "Accepting with params: f_xn=tensor(-631.4825), f_x0=tensor(-631.2491), alpha=tensor(0.4751)\n",
      "Accepting with params: f_xn=tensor(-631.3887), f_x0=tensor(-631.4825), alpha=tensor(0.6590)\n",
      "Accepting with params: f_xn=tensor(-631.4866), f_x0=tensor(-631.3887), alpha=tensor(0.5440)\n",
      "Accepting with params: f_xn=tensor(-632.2084), f_x0=tensor(-631.4866), alpha=tensor(0.2915)\n",
      "Accepting with params: f_xn=tensor(-632.7601), f_x0=tensor(-632.2084), alpha=tensor(0.3456)\n",
      "Accepting with params: f_xn=tensor(-632.0468), f_x0=tensor(-632.7601), alpha=tensor(1.2244)\n",
      "Accepting with params: f_xn=tensor(-632.3430), f_x0=tensor(-632.0468), alpha=tensor(0.4462)\n",
      "Accepting with params: f_xn=tensor(-632.4504), f_x0=tensor(-632.3430), alpha=tensor(0.5389)\n",
      "Accepting with params: f_xn=tensor(-632.9936), f_x0=tensor(-632.4504), alpha=tensor(0.3485)\n",
      "Accepting with params: f_xn=tensor(-633.1273), f_x0=tensor(-632.9936), alpha=tensor(0.5249)\n",
      "Accepting with params: f_xn=tensor(-633.2948), f_x0=tensor(-633.1273), alpha=tensor(0.5074)\n",
      "Accepting with params: f_xn=tensor(-633.9031), f_x0=tensor(-633.2948), alpha=tensor(0.3266)\n",
      "Accepting with params: f_xn=tensor(-632.5975), f_x0=tensor(-633.9031), alpha=tensor(2.2139)\n",
      "Accepting with params: f_xn=tensor(-632.9295), f_x0=tensor(-632.5975), alpha=tensor(0.4305)\n",
      "Accepting with params: f_xn=tensor(-632.8604), f_x0=tensor(-632.9295), alpha=tensor(0.6430)\n",
      "Accepting with params: f_xn=tensor(-632.4222), f_x0=tensor(-632.8604), alpha=tensor(0.9299)\n",
      "Accepting with params: f_xn=tensor(-632.5278), f_x0=tensor(-632.4222), alpha=tensor(0.5399)\n",
      "Accepting with params: f_xn=tensor(-632.0203), f_x0=tensor(-632.5278), alpha=tensor(0.9967)\n",
      "Accepting with params: f_xn=tensor(-632.2366), f_x0=tensor(-632.0203), alpha=tensor(0.4833)\n",
      "Accepting with params: f_xn=tensor(-632.2908), f_x0=tensor(-632.2366), alpha=tensor(0.5683)\n",
      "Accepting with params: f_xn=tensor(-632.5828), f_x0=tensor(-632.2908), alpha=tensor(0.4481)\n",
      "Accepting with params: f_xn=tensor(-632.5351), f_x0=tensor(-632.5828), alpha=tensor(0.6293)\n",
      "Accepting with params: f_xn=tensor(-633.0949), f_x0=tensor(-632.5351), alpha=tensor(0.3428)\n",
      "Accepting with params: f_xn=tensor(-632.4534), f_x0=tensor(-633.0949), alpha=tensor(1.1396)\n",
      "Accepting with params: f_xn=tensor(-632.0829), f_x0=tensor(-632.4534), alpha=tensor(0.8690)\n",
      "Accepting with params: f_xn=tensor(-631.9488), f_x0=tensor(-632.0829), alpha=tensor(0.6861)\n",
      "Accepting with params: f_xn=tensor(-631.9194), f_x0=tensor(-631.9488), alpha=tensor(0.6179)\n",
      "Accepting with params: f_xn=tensor(-632.6758), f_x0=tensor(-631.9194), alpha=tensor(0.2816)\n",
      "Accepting with params: f_xn=tensor(-632.1298), f_x0=tensor(-632.6758), alpha=tensor(1.0359)\n",
      "Accepting with params: f_xn=tensor(-632.2590), f_x0=tensor(-632.1298), alpha=tensor(0.5272)\n",
      "Accepting with params: f_xn=tensor(-632.0337), f_x0=tensor(-632.2590), alpha=tensor(0.7517)\n",
      "Accepting with params: f_xn=tensor(-633.9534), f_x0=tensor(-632.0337), alpha=tensor(0.0880)\n",
      "Accepting with params: f_xn=tensor(-633.8875), f_x0=tensor(-633.9534), alpha=tensor(0.6408)\n",
      "Accepting with params: f_xn=tensor(-633.6059), f_x0=tensor(-633.8875), alpha=tensor(0.7952)\n",
      "Accepting with params: f_xn=tensor(-632.2486), f_x0=tensor(-633.6059), alpha=tensor(2.3314)\n",
      "Accepting with params: f_xn=tensor(-631.8917), f_x0=tensor(-632.2486), alpha=tensor(0.8574)\n",
      "Accepting with params: f_xn=tensor(-631.8123), f_x0=tensor(-631.8917), alpha=tensor(0.6495)\n",
      "Accepting with params: f_xn=tensor(-631.9470), f_x0=tensor(-631.8123), alpha=tensor(0.5244)\n",
      "Accepting with params: f_xn=tensor(-632.9406), f_x0=tensor(-631.9470), alpha=tensor(0.2221)\n",
      "Accepting with params: f_xn=tensor(-632.1810), f_x0=tensor(-632.9406), alpha=tensor(1.2824)\n",
      "Accepting with params: f_xn=tensor(-632.4082), f_x0=tensor(-632.1810), alpha=tensor(0.4781)\n",
      "Accepting with params: f_xn=tensor(-634.2832), f_x0=tensor(-632.4082), alpha=tensor(0.0920)\n",
      "Accepting with params: f_xn=tensor(-632.7473), f_x0=tensor(-634.2832), alpha=tensor(2.7874)\n",
      "Accepting with params: f_xn=tensor(-634.6486), f_x0=tensor(-632.7473), alpha=tensor(0.0896)\n",
      "Accepting with params: f_xn=tensor(-631.9512), f_x0=tensor(-634.6486), alpha=tensor(8.9051)\n",
      "Accepting with params: f_xn=tensor(-631.7780), f_x0=tensor(-631.9512), alpha=tensor(0.7134)\n",
      "Accepting with params: f_xn=tensor(-631.8118), f_x0=tensor(-631.7780), alpha=tensor(0.5801)\n",
      "Accepting with params: f_xn=tensor(-632.2841), f_x0=tensor(-631.8118), alpha=tensor(0.3741)\n",
      "Accepting with params: f_xn=tensor(-633.2495), f_x0=tensor(-632.2841), alpha=tensor(0.2285)\n",
      "Accepting with params: f_xn=tensor(-631.9050), f_x0=tensor(-633.2495), alpha=tensor(2.3017)\n",
      "Accepting with params: f_xn=tensor(-631.9019), f_x0=tensor(-631.9050), alpha=tensor(0.6018)\n",
      "Accepting with params: f_xn=tensor(-633.4623), f_x0=tensor(-631.9019), alpha=tensor(0.1260)\n",
      "Accepting with params: f_xn=tensor(-632.1917), f_x0=tensor(-633.4623), alpha=tensor(2.1379)\n",
      "Accepting with params: f_xn=tensor(-632.9056), f_x0=tensor(-632.1917), alpha=tensor(0.2938)\n",
      "Accepting with params: f_xn=tensor(-632.5888), f_x0=tensor(-632.9056), alpha=tensor(0.8237)\n",
      "Accepting with params: f_xn=tensor(-632.6436), f_x0=tensor(-632.5888), alpha=tensor(0.5680)\n",
      "Accepting with params: f_xn=tensor(-632.5353), f_x0=tensor(-632.6436), alpha=tensor(0.6686)\n",
      "Accepting with params: f_xn=tensor(-633.2274), f_x0=tensor(-632.5353), alpha=tensor(0.3003)\n",
      "Accepting with params: f_xn=tensor(-633.0034), f_x0=tensor(-633.2274), alpha=tensor(0.7506)\n",
      "Accepting with params: f_xn=tensor(-633.3941), f_x0=tensor(-633.0034), alpha=tensor(0.4059)\n",
      "Accepting with params: f_xn=tensor(-633.0179), f_x0=tensor(-633.3941), alpha=tensor(0.8740)\n",
      "Accepting with params: f_xn=tensor(-632.9907), f_x0=tensor(-633.0179), alpha=tensor(0.6166)\n",
      "Accepting with params: f_xn=tensor(-633.1320), f_x0=tensor(-632.9907), alpha=tensor(0.5209)\n",
      "Accepting with params: f_xn=tensor(-634.7105), f_x0=tensor(-633.1320), alpha=tensor(0.1238)\n",
      "Accepting with params: f_xn=tensor(-634.0236), f_x0=tensor(-634.7105), alpha=tensor(1.1925)\n",
      "Accepting with params: f_xn=tensor(-634.5894), f_x0=tensor(-634.0236), alpha=tensor(0.3407)\n",
      "Accepting with params: f_xn=tensor(-634.4300), f_x0=tensor(-634.5894), alpha=tensor(0.7037)\n",
      "Accepting with params: f_xn=tensor(-634.8998), f_x0=tensor(-634.4300), alpha=tensor(0.3751)\n",
      "Accepting with params: f_xn=tensor(-635.2214), f_x0=tensor(-634.8998), alpha=tensor(0.4350)\n",
      "Accepting with params: f_xn=tensor(-634.5328), f_x0=tensor(-635.2214), alpha=tensor(1.1945)\n",
      "Accepting with params: f_xn=tensor(-634.0548), f_x0=tensor(-634.5328), alpha=tensor(0.9677)\n",
      "Accepting with params: f_xn=tensor(-636.3889), f_x0=tensor(-634.0548), alpha=tensor(0.0581)\n",
      "Accepting with params: f_xn=tensor(-634.6369), f_x0=tensor(-636.3889), alpha=tensor(3.4597)\n",
      "Accepting with params: f_xn=tensor(-634.3110), f_x0=tensor(-634.6369), alpha=tensor(0.8311)\n",
      "Accepting with params: f_xn=tensor(-633.8103), f_x0=tensor(-634.3110), alpha=tensor(0.9900)\n",
      "Accepting with params: f_xn=tensor(-635.2567), f_x0=tensor(-633.8103), alpha=tensor(0.1412)\n",
      "Accepting with params: f_xn=tensor(-634.7718), f_x0=tensor(-635.2567), alpha=tensor(0.9744)\n",
      "Accepting with params: f_xn=tensor(-635.3881), f_x0=tensor(-634.7718), alpha=tensor(0.3240)\n",
      "Accepting with params: f_xn=tensor(-635.7075), f_x0=tensor(-635.3881), alpha=tensor(0.4359)\n",
      "Accepting with params: f_xn=tensor(-635.7667), f_x0=tensor(-635.7075), alpha=tensor(0.5655)\n",
      "Accepting with params: f_xn=tensor(-634.6631), f_x0=tensor(-635.7667), alpha=tensor(1.8088)\n",
      "Accepting with params: f_xn=tensor(-635.2384), f_x0=tensor(-634.6631), alpha=tensor(0.3375)\n",
      "Accepting with params: f_xn=tensor(-635.4548), f_x0=tensor(-635.2384), alpha=tensor(0.4832)\n",
      "Accepting with params: f_xn=tensor(-635.1389), f_x0=tensor(-635.4548), alpha=tensor(0.8229)\n",
      "Accepting with params: f_xn=tensor(-634.4630), f_x0=tensor(-635.1389), alpha=tensor(1.1796)\n",
      "Accepting with params: f_xn=tensor(-636.5294), f_x0=tensor(-634.4630), alpha=tensor(0.0760)\n",
      "Accepting with params: f_xn=tensor(-634.2966), f_x0=tensor(-636.5294), alpha=tensor(5.5955)\n",
      "Accepting with params: f_xn=tensor(-634.2427), f_x0=tensor(-634.2966), alpha=tensor(0.6332)\n",
      "Accepting with params: f_xn=tensor(-634.7584), f_x0=tensor(-634.2427), alpha=tensor(0.3583)\n",
      "Accepting with params: f_xn=tensor(-634.9966), f_x0=tensor(-634.7584), alpha=tensor(0.4728)\n",
      "Accepting with params: f_xn=tensor(-635.1168), f_x0=tensor(-634.9966), alpha=tensor(0.5321)\n",
      "Accepting with params: f_xn=tensor(-636.8079), f_x0=tensor(-635.1168), alpha=tensor(0.1106)\n",
      "Accepting with params: f_xn=tensor(-635.3041), f_x0=tensor(-636.8079), alpha=tensor(2.6992)\n",
      "Accepting with params: f_xn=tensor(-635.0425), f_x0=tensor(-635.3041), alpha=tensor(0.7794)\n",
      "Accepting with params: f_xn=tensor(-635.4130), f_x0=tensor(-635.0425), alpha=tensor(0.4143)\n",
      "Accepting with params: f_xn=tensor(-635.4813), f_x0=tensor(-635.4130), alpha=tensor(0.5604)\n",
      "Accepting with params: f_xn=tensor(-635.1040), f_x0=tensor(-635.4813), alpha=tensor(0.8750)\n",
      "Accepting with params: f_xn=tensor(-634.9385), f_x0=tensor(-635.1040), alpha=tensor(0.7080)\n",
      "Accepting with params: f_xn=tensor(-634.8176), f_x0=tensor(-634.9385), alpha=tensor(0.6771)\n",
      "Accepting with params: f_xn=tensor(-635.3757), f_x0=tensor(-634.8176), alpha=tensor(0.3434)\n",
      "Accepting with params: f_xn=tensor(-635.2196), f_x0=tensor(-635.3757), alpha=tensor(0.7014)\n",
      "Accepting with params: f_xn=tensor(-634.8848), f_x0=tensor(-635.2196), alpha=tensor(0.8386)\n",
      "Accepting with params: f_xn=tensor(-635.1777), f_x0=tensor(-634.8848), alpha=tensor(0.4477)\n",
      "Accepting with params: f_xn=tensor(-634.7359), f_x0=tensor(-635.1777), alpha=tensor(0.9333)\n",
      "Accepting with params: f_xn=tensor(-635.1090), f_x0=tensor(-634.7359), alpha=tensor(0.4132)\n",
      "Accepting with params: f_xn=tensor(-637.6340), f_x0=tensor(-635.1090), alpha=tensor(0.0480)\n",
      "Accepting with params: f_xn=tensor(-634.8013), f_x0=tensor(-637.6340), alpha=tensor(10.1954)\n",
      "Accepting with params: f_xn=tensor(-634.8937), f_x0=tensor(-634.8013), alpha=tensor(0.5470)\n",
      "Accepting with params: f_xn=tensor(-634.7602), f_x0=tensor(-634.8937), alpha=tensor(0.6857)\n",
      "Accepting with params: f_xn=tensor(-634.2523), f_x0=tensor(-634.7602), alpha=tensor(0.9971)\n",
      "Accepting with params: f_xn=tensor(-635.1951), f_x0=tensor(-634.2523), alpha=tensor(0.2337)\n",
      "Accepting with params: f_xn=tensor(-634.1333), f_x0=tensor(-635.1951), alpha=tensor(1.7350)\n",
      "Accepting with params: f_xn=tensor(-633.3696), f_x0=tensor(-634.1333), alpha=tensor(1.2877)\n",
      "Accepting with params: f_xn=tensor(-633.6309), f_x0=tensor(-633.3696), alpha=tensor(0.4620)\n",
      "Accepting with params: f_xn=tensor(-633.8238), f_x0=tensor(-633.6309), alpha=tensor(0.4948)\n",
      "Accepting with params: f_xn=tensor(-635.1835), f_x0=tensor(-633.8238), alpha=tensor(0.1540)\n",
      "Accepting with params: f_xn=tensor(-634.6304), f_x0=tensor(-635.1835), alpha=tensor(1.0431)\n",
      "Accepting with params: f_xn=tensor(-634.9469), f_x0=tensor(-634.6304), alpha=tensor(0.4372)\n",
      "Accepting with params: f_xn=tensor(-635.0546), f_x0=tensor(-634.9469), alpha=tensor(0.5387)\n",
      "Accepting with params: f_xn=tensor(-634.6432), f_x0=tensor(-635.0546), alpha=tensor(0.9054)\n",
      "Accepting with params: f_xn=tensor(-634.6311), f_x0=tensor(-634.6432), alpha=tensor(0.6073)\n",
      "Accepting with params: f_xn=tensor(-634.9656), f_x0=tensor(-634.6311), alpha=tensor(0.4294)\n",
      "Accepting with params: f_xn=tensor(-634.5621), f_x0=tensor(-634.9656), alpha=tensor(0.8983)\n",
      "Accepting with params: f_xn=tensor(-634.3889), f_x0=tensor(-634.5621), alpha=tensor(0.7134)\n",
      "Accepting with params: f_xn=tensor(-634.1108), f_x0=tensor(-634.3889), alpha=tensor(0.7924)\n",
      "Accepting with params: f_xn=tensor(-634.2747), f_x0=tensor(-634.1108), alpha=tensor(0.5093)\n",
      "Accepting with params: f_xn=tensor(-633.5227), f_x0=tensor(-634.2747), alpha=tensor(1.2727)\n",
      "Accepting with params: f_xn=tensor(-633.4481), f_x0=tensor(-633.5227), alpha=tensor(0.6465)\n",
      "Accepting with params: f_xn=tensor(-634.5504), f_x0=tensor(-633.4481), alpha=tensor(0.1993)\n",
      "Accepting with params: f_xn=tensor(-634.3915), f_x0=tensor(-634.5504), alpha=tensor(0.7033)\n",
      "Accepting with params: f_xn=tensor(-634.4189), f_x0=tensor(-634.3915), alpha=tensor(0.5838)\n",
      "Accepting with params: f_xn=tensor(-634.5992), f_x0=tensor(-634.4189), alpha=tensor(0.5010)\n",
      "Accepting with params: f_xn=tensor(-633.6163), f_x0=tensor(-634.5992), alpha=tensor(1.6033)\n",
      "Accepting with params: f_xn=tensor(-633.6635), f_x0=tensor(-633.6163), alpha=tensor(0.5723)\n",
      "Accepting with params: f_xn=tensor(-633.2541), f_x0=tensor(-633.6635), alpha=tensor(0.9035)\n",
      "Accepting with params: f_xn=tensor(-633.1665), f_x0=tensor(-633.2541), alpha=tensor(0.6549)\n",
      "Accepting with params: f_xn=tensor(-633.5614), f_x0=tensor(-633.1665), alpha=tensor(0.4042)\n",
      "Accepting with params: f_xn=tensor(-633.3586), f_x0=tensor(-633.5614), alpha=tensor(0.7349)\n",
      "Accepting with params: f_xn=tensor(-633.8319), f_x0=tensor(-633.3586), alpha=tensor(0.3738)\n",
      "Accepting with params: f_xn=tensor(-634.0903), f_x0=tensor(-633.8319), alpha=tensor(0.4634)\n",
      "Accepting with params: f_xn=tensor(-633.9988), f_x0=tensor(-634.0903), alpha=tensor(0.6575)\n",
      "Accepting with params: f_xn=tensor(-634.4488), f_x0=tensor(-633.9988), alpha=tensor(0.3826)\n",
      "Accepting with params: f_xn=tensor(-634.6235), f_x0=tensor(-634.4488), alpha=tensor(0.5038)\n",
      "Accepting with params: f_xn=tensor(-637.5647), f_x0=tensor(-634.6235), alpha=tensor(0.0317)\n",
      "Accepting with params: f_xn=tensor(-634.3248), f_x0=tensor(-637.5647), alpha=tensor(15.3191)\n",
      "Accepting with params: f_xn=tensor(-634.3594), f_x0=tensor(-634.3248), alpha=tensor(0.5796)\n",
      "Accepting with params: f_xn=tensor(-634.4423), f_x0=tensor(-634.3594), alpha=tensor(0.5522)\n",
      "Accepting with params: f_xn=tensor(-634.8103), f_x0=tensor(-634.4423), alpha=tensor(0.4153)\n",
      "Accepting with params: f_xn=tensor(-634.9229), f_x0=tensor(-634.8103), alpha=tensor(0.5361)\n",
      "Accepting with params: f_xn=tensor(-634.7650), f_x0=tensor(-634.9229), alpha=tensor(0.7027)\n",
      "Accepting with params: f_xn=tensor(-635.8990), f_x0=tensor(-634.7650), alpha=tensor(0.1930)\n",
      "Accepting with params: f_xn=tensor(-636.3297), f_x0=tensor(-635.8990), alpha=tensor(0.3900)\n",
      "Accepting with params: f_xn=tensor(-636.1130), f_x0=tensor(-636.3297), alpha=tensor(0.7451)\n",
      "Accepting with params: f_xn=tensor(-636.3954), f_x0=tensor(-636.1130), alpha=tensor(0.4524)\n",
      "Accepting with params: f_xn=tensor(-635.6550), f_x0=tensor(-636.3954), alpha=tensor(1.2581)\n",
      "Accepting with params: f_xn=tensor(-636.0289), f_x0=tensor(-635.6550), alpha=tensor(0.4128)\n",
      "Accepting with params: f_xn=tensor(-636.4582), f_x0=tensor(-636.0289), alpha=tensor(0.3906)\n",
      "Accepting with params: f_xn=tensor(-636.5549), f_x0=tensor(-636.4582), alpha=tensor(0.5447)\n",
      "Accepting with params: f_xn=tensor(-636.6709), f_x0=tensor(-636.5549), alpha=tensor(0.5343)\n",
      "Accepting with params: f_xn=tensor(-636.9937), f_x0=tensor(-636.6709), alpha=tensor(0.4345)\n",
      "Accepting with params: f_xn=tensor(-636.7559), f_x0=tensor(-636.9937), alpha=tensor(0.7611)\n",
      "Accepting with params: f_xn=tensor(-636.7951), f_x0=tensor(-636.7559), alpha=tensor(0.5769)\n",
      "Accepting with params: f_xn=tensor(-636.7881), f_x0=tensor(-636.7951), alpha=tensor(0.6042)\n",
      "Accepting with params: f_xn=tensor(-637.1288), f_x0=tensor(-636.7881), alpha=tensor(0.4267)\n",
      "Accepting with params: f_xn=tensor(-637.4515), f_x0=tensor(-637.1288), alpha=tensor(0.4345)\n",
      "Accepting with params: f_xn=tensor(-636.8671), f_x0=tensor(-637.4515), alpha=tensor(1.0764)\n",
      "Accepting with params: f_xn=tensor(-636.7166), f_x0=tensor(-636.8671), alpha=tensor(0.6975)\n",
      "Accepting with params: f_xn=tensor(-638.0941), f_x0=tensor(-636.7166), alpha=tensor(0.1513)\n",
      "Accepting with params: f_xn=tensor(-637.4000), f_x0=tensor(-638.0941), alpha=tensor(1.2011)\n",
      "Accepting with params: f_xn=tensor(-638.9439), f_x0=tensor(-637.4000), alpha=tensor(0.1281)\n",
      "Accepting with params: f_xn=tensor(-637.7917), f_x0=tensor(-638.9439), alpha=tensor(1.8990)\n",
      "Accepting with params: f_xn=tensor(-638.1182), f_x0=tensor(-637.7917), alpha=tensor(0.4329)\n",
      "Accepting with params: f_xn=tensor(-638.2250), f_x0=tensor(-638.1182), alpha=tensor(0.5392)\n",
      "Accepting with params: f_xn=tensor(-637.1715), f_x0=tensor(-638.2250), alpha=tensor(1.7205)\n",
      "Accepting with params: f_xn=tensor(-637.7164), f_x0=tensor(-637.1715), alpha=tensor(0.3480)\n",
      "Accepting with params: f_xn=tensor(-637.8007), f_x0=tensor(-637.7164), alpha=tensor(0.5515)\n",
      "Accepting with params: f_xn=tensor(-637.3474), f_x0=tensor(-637.8007), alpha=tensor(0.9442)\n",
      "Accepting with params: f_xn=tensor(-636.7083), f_x0=tensor(-637.3474), alpha=tensor(1.1369)\n",
      "Accepting with params: f_xn=tensor(-638.1605), f_x0=tensor(-636.7083), alpha=tensor(0.1404)\n",
      "Accepting with params: f_xn=tensor(-637.0562), f_x0=tensor(-638.1605), alpha=tensor(1.8104)\n",
      "Accepting with params: f_xn=tensor(-637.4203), f_x0=tensor(-637.0562), alpha=tensor(0.4169)\n",
      "Accepting with params: f_xn=tensor(-636.4205), f_x0=tensor(-637.4203), alpha=tensor(1.6307)\n",
      "Accepting with params: f_xn=tensor(-639.8110), f_x0=tensor(-636.4205), alpha=tensor(0.0202)\n",
      "Accepting with params: f_xn=tensor(-636.7047), f_x0=tensor(-639.8110), alpha=tensor(13.4033)\n",
      "Accepting with params: f_xn=tensor(-637.2884), f_x0=tensor(-636.7047), alpha=tensor(0.3347)\n",
      "Accepting with params: f_xn=tensor(-637.8237), f_x0=tensor(-637.2884), alpha=tensor(0.3513)\n",
      "Accepting with params: f_xn=tensor(-638.2316), f_x0=tensor(-637.8237), alpha=tensor(0.3991)\n",
      "Accepting with params: f_xn=tensor(-637.5839), f_x0=tensor(-638.2316), alpha=tensor(1.1467)\n",
      "Accepting with params: f_xn=tensor(-637.6085), f_x0=tensor(-637.5839), alpha=tensor(0.5854)\n",
      "Accepting with params: f_xn=tensor(-638.0374), f_x0=tensor(-637.6085), alpha=tensor(0.3907)\n",
      "Accepting with params: f_xn=tensor(-641.0234), f_x0=tensor(-638.0374), alpha=tensor(0.0303)\n",
      "Accepting with params: f_xn=tensor(-639.0717), f_x0=tensor(-641.0234), alpha=tensor(4.2245)\n",
      "Accepting with params: f_xn=tensor(-638.4005), f_x0=tensor(-639.0717), alpha=tensor(1.1740)\n",
      "Accepting with params: f_xn=tensor(-639.9732), f_x0=tensor(-638.4005), alpha=tensor(0.1245)\n",
      "Accepting with params: f_xn=tensor(-640.0575), f_x0=tensor(-639.9732), alpha=tensor(0.5515)\n",
      "Accepting with params: f_xn=tensor(-636.4509), f_x0=tensor(-640.0575), alpha=tensor(22.1036)\n",
      "Accepting with params: f_xn=tensor(-636.3006), f_x0=tensor(-636.4509), alpha=tensor(0.6973)\n",
      "Accepting with params: f_xn=tensor(-636.2627), f_x0=tensor(-636.3006), alpha=tensor(0.6232)\n",
      "Accepting with params: f_xn=tensor(-636.5956), f_x0=tensor(-636.2627), alpha=tensor(0.4301)\n",
      "Accepting with params: f_xn=tensor(-636.9053), f_x0=tensor(-636.5956), alpha=tensor(0.4402)\n",
      "Accepting with params: f_xn=tensor(-636.7401), f_x0=tensor(-636.9053), alpha=tensor(0.7078)\n",
      "Accepting with params: f_xn=tensor(-636.9850), f_x0=tensor(-636.7401), alpha=tensor(0.4696)\n",
      "Accepting with params: f_xn=tensor(-635.6329), f_x0=tensor(-636.9850), alpha=tensor(2.3193)\n",
      "Accepting with params: f_xn=tensor(-635.2522), f_x0=tensor(-635.6329), alpha=tensor(0.8780)\n",
      "Accepting with params: f_xn=tensor(-634.7379), f_x0=tensor(-635.2522), alpha=tensor(1.0035)\n",
      "Accepting with params: f_xn=tensor(-638.6848), f_x0=tensor(-634.7379), alpha=tensor(0.0116)\n",
      "Accepting with params: f_xn=tensor(-638.8164), f_x0=tensor(-638.6848), alpha=tensor(0.5260)\n",
      "Accepting with params: f_xn=tensor(-637.3544), f_x0=tensor(-638.8164), alpha=tensor(2.5887)\n",
      "Accepting with params: f_xn=tensor(-636.3653), f_x0=tensor(-637.3544), alpha=tensor(1.6133)\n",
      "Accepting with params: f_xn=tensor(-634.9808), f_x0=tensor(-636.3653), alpha=tensor(2.3957)\n",
      "Accepting with params: f_xn=tensor(-635.5154), f_x0=tensor(-634.9808), alpha=tensor(0.3515)\n",
      "Accepting with params: f_xn=tensor(-635.5328), f_x0=tensor(-635.5154), alpha=tensor(0.5897)\n",
      "Accepting with params: f_xn=tensor(-635.9636), f_x0=tensor(-635.5328), alpha=tensor(0.3900)\n",
      "Accepting with params: f_xn=tensor(-636.9579), f_x0=tensor(-635.9636), alpha=tensor(0.2220)\n",
      "Accepting with params: f_xn=tensor(-637.3518), f_x0=tensor(-636.9579), alpha=tensor(0.4046)\n",
      "Accepting with params: f_xn=tensor(-635.9332), f_x0=tensor(-637.3518), alpha=tensor(2.4787)\n",
      "Accepting with params: f_xn=tensor(-636.1040), f_x0=tensor(-635.9332), alpha=tensor(0.5058)\n",
      "Accepting with params: f_xn=tensor(-636.4646), f_x0=tensor(-636.1040), alpha=tensor(0.4184)\n",
      "Accepting with params: f_xn=tensor(-637.2405), f_x0=tensor(-636.4646), alpha=tensor(0.2762)\n",
      "Accepting with params: f_xn=tensor(-637.0113), f_x0=tensor(-637.2405), alpha=tensor(0.7546)\n",
      "Accepting with params: f_xn=tensor(-637.8552), f_x0=tensor(-637.0113), alpha=tensor(0.2580)\n",
      "Accepting with params: f_xn=tensor(-637.5556), f_x0=tensor(-637.8552), alpha=tensor(0.8096)\n",
      "Accepting with params: f_xn=tensor(-636.8291), f_x0=tensor(-637.5556), alpha=tensor(1.2407)\n",
      "Accepting with params: f_xn=tensor(-637.2009), f_x0=tensor(-636.8291), alpha=tensor(0.4137)\n",
      "Accepting with params: f_xn=tensor(-636.8574), f_x0=tensor(-637.2009), alpha=tensor(0.8459)\n",
      "Accepting with params: f_xn=tensor(-636.7018), f_x0=tensor(-636.8574), alpha=tensor(0.7010)\n",
      "Accepting with params: f_xn=tensor(-637.7169), f_x0=tensor(-636.7018), alpha=tensor(0.2174)\n",
      "Accepting with params: f_xn=tensor(-637.3364), f_x0=tensor(-637.7169), alpha=tensor(0.8779)\n",
      "Accepting with params: f_xn=tensor(-637.7626), f_x0=tensor(-637.3364), alpha=tensor(0.3918)\n",
      "Accepting with params: f_xn=tensor(-638.4279), f_x0=tensor(-637.7626), alpha=tensor(0.3085)\n",
      "Accepting with params: f_xn=tensor(-638.7610), f_x0=tensor(-638.4279), alpha=tensor(0.4300)\n",
      "Accepting with params: f_xn=tensor(-637.1041), f_x0=tensor(-638.7610), alpha=tensor(3.1459)\n",
      "Accepting with params: f_xn=tensor(-637.0698), f_x0=tensor(-637.1041), alpha=tensor(0.6209)\n",
      "Accepting with params: f_xn=tensor(-637.2646), f_x0=tensor(-637.0698), alpha=tensor(0.4938)\n",
      "Accepting with params: f_xn=tensor(-636.7466), f_x0=tensor(-637.2646), alpha=tensor(1.0072)\n",
      "Accepting with params: f_xn=tensor(-636.2676), f_x0=tensor(-636.7466), alpha=tensor(0.9687)\n",
      "Accepting with params: f_xn=tensor(-635.6710), f_x0=tensor(-636.2676), alpha=tensor(1.0896)\n",
      "Accepting with params: f_xn=tensor(-636.4648), f_x0=tensor(-635.6710), alpha=tensor(0.2713)\n",
      "Accepting with params: f_xn=tensor(-637.5049), f_x0=tensor(-636.4648), alpha=tensor(0.2120)\n",
      "Accepting with params: f_xn=tensor(-635.3172), f_x0=tensor(-637.5049), alpha=tensor(5.3490)\n",
      "Accepting with params: f_xn=tensor(-635.9759), f_x0=tensor(-635.3172), alpha=tensor(0.3105)\n",
      "Accepting with params: f_xn=tensor(-635.7672), f_x0=tensor(-635.9759), alpha=tensor(0.7392)\n",
      "Accepting with params: f_xn=tensor(-635.9290), f_x0=tensor(-635.7672), alpha=tensor(0.5104)\n",
      "Accepting with params: f_xn=tensor(-636.6760), f_x0=tensor(-635.9290), alpha=tensor(0.2843)\n",
      "Accepting with params: f_xn=tensor(-636.0984), f_x0=tensor(-636.6760), alpha=tensor(1.0690)\n",
      "Accepting with params: f_xn=tensor(-636.1556), f_x0=tensor(-636.0984), alpha=tensor(0.5666)\n",
      "Accepting with params: f_xn=tensor(-636.8372), f_x0=tensor(-636.1556), alpha=tensor(0.3035)\n",
      "Accepting with params: f_xn=tensor(-637.6608), f_x0=tensor(-636.8372), alpha=tensor(0.2633)\n",
      "Accepting with params: f_xn=tensor(-638.4453), f_x0=tensor(-637.6608), alpha=tensor(0.2738)\n",
      "Accepting with params: f_xn=tensor(-636.7967), f_x0=tensor(-638.4453), alpha=tensor(3.1199)\n",
      "Accepting with params: f_xn=tensor(-636.4946), f_x0=tensor(-636.7967), alpha=tensor(0.8116)\n",
      "Accepting with params: f_xn=tensor(-637.0319), f_x0=tensor(-636.4946), alpha=tensor(0.3506)\n",
      "Accepting with params: f_xn=tensor(-636.3757), f_x0=tensor(-637.0319), alpha=tensor(1.1565)\n",
      "Accepting with params: f_xn=tensor(-636.3840), f_x0=tensor(-636.3757), alpha=tensor(0.5950)\n",
      "Accepting with params: f_xn=tensor(-635.7089), f_x0=tensor(-636.3840), alpha=tensor(1.1786)\n",
      "Accepting with params: f_xn=tensor(-637.7078), f_x0=tensor(-635.7089), alpha=tensor(0.0813)\n",
      "Accepting with params: f_xn=tensor(-634.6245), f_x0=tensor(-637.7078), alpha=tensor(13.0984)\n",
      "Accepting with params: f_xn=tensor(-634.2634), f_x0=tensor(-634.6245), alpha=tensor(0.8609)\n",
      "Accepting with params: f_xn=tensor(-636.6499), f_x0=tensor(-634.2634), alpha=tensor(0.0552)\n",
      "Accepting with params: f_xn=tensor(-637.1064), f_x0=tensor(-636.6499), alpha=tensor(0.3801)\n",
      "Accepting with params: f_xn=tensor(-636.6852), f_x0=tensor(-637.1064), alpha=tensor(0.9143)\n",
      "Accepting with params: f_xn=tensor(-635.5196), f_x0=tensor(-636.6852), alpha=tensor(1.9248)\n",
      "Accepting with params: f_xn=tensor(-635.5750), f_x0=tensor(-635.5196), alpha=tensor(0.5677)\n",
      "Accepting with params: f_xn=tensor(-635.5316), f_x0=tensor(-635.5750), alpha=tensor(0.6266)\n",
      "Accepting with params: f_xn=tensor(-635.3937), f_x0=tensor(-635.5316), alpha=tensor(0.6887)\n",
      "Accepting with params: f_xn=tensor(-636.7850), f_x0=tensor(-635.3937), alpha=tensor(0.1493)\n",
      "Accepting with params: f_xn=tensor(-638.0465), f_x0=tensor(-636.7850), alpha=tensor(0.1699)\n",
      "Accepting with params: f_xn=tensor(-635.9127), f_x0=tensor(-638.0465), alpha=tensor(5.0681)\n",
      "Accepting with params: f_xn=tensor(-635.7326), f_x0=tensor(-635.9127), alpha=tensor(0.7184)\n",
      "Accepting with params: f_xn=tensor(-636.0664), f_x0=tensor(-635.7326), alpha=tensor(0.4297)\n",
      "Accepting with params: f_xn=tensor(-635.6425), f_x0=tensor(-636.0664), alpha=tensor(0.9168)\n",
      "Accepting with params: f_xn=tensor(-635.3231), f_x0=tensor(-635.6425), alpha=tensor(0.8258)\n",
      "Accepting with params: f_xn=tensor(-635.7916), f_x0=tensor(-635.3231), alpha=tensor(0.3756)\n",
      "Accepting with params: f_xn=tensor(-635.7292), f_x0=tensor(-635.7916), alpha=tensor(0.6386)\n",
      "Accepting with params: f_xn=tensor(-635.1713), f_x0=tensor(-635.7292), alpha=tensor(1.0482)\n",
      "Accepting with params: f_xn=tensor(-635.2191), f_x0=tensor(-635.1713), alpha=tensor(0.5720)\n",
      "Accepting with params: f_xn=tensor(-634.9808), f_x0=tensor(-635.2191), alpha=tensor(0.7614)\n",
      "Accepting with params: f_xn=tensor(-637.1390), f_x0=tensor(-634.9808), alpha=tensor(0.0693)\n",
      "Accepting with params: f_xn=tensor(-636.3734), f_x0=tensor(-637.1390), alpha=tensor(1.2901)\n",
      "Accepting with params: f_xn=tensor(-636.9188), f_x0=tensor(-636.3734), alpha=tensor(0.3478)\n",
      "Accepting with params: f_xn=tensor(-636.8810), f_x0=tensor(-636.9188), alpha=tensor(0.6231)\n",
      "Accepting with params: f_xn=tensor(-637.5393), f_x0=tensor(-636.8810), alpha=tensor(0.3106)\n",
      "Accepting with params: f_xn=tensor(-637.7939), f_x0=tensor(-637.5393), alpha=tensor(0.4651)\n",
      "Accepting with params: f_xn=tensor(-638.1167), f_x0=tensor(-637.7939), alpha=tensor(0.4345)\n",
      "Accepting with params: f_xn=tensor(-640.9946), f_x0=tensor(-638.1167), alpha=tensor(0.0338)\n",
      "Accepting with params: f_xn=tensor(-641.6516), f_x0=tensor(-640.9946), alpha=tensor(0.3110)\n",
      "Accepting with params: f_xn=tensor(-639.3905), f_x0=tensor(-641.6516), alpha=tensor(5.7562)\n",
      "Accepting with params: f_xn=tensor(-639.5083), f_x0=tensor(-639.3905), alpha=tensor(0.5333)\n",
      "Accepting with params: f_xn=tensor(-638.8165), f_x0=tensor(-639.5083), alpha=tensor(1.1984)\n",
      "Accepting with params: f_xn=tensor(-638.7000), f_x0=tensor(-638.8165), alpha=tensor(0.6741)\n",
      "Accepting with params: f_xn=tensor(-638.0070), f_x0=tensor(-638.7000), alpha=tensor(1.1998)\n",
      "Accepting with params: f_xn=tensor(-637.5277), f_x0=tensor(-638.0070), alpha=tensor(0.9690)\n",
      "Accepting with params: f_xn=tensor(-637.5743), f_x0=tensor(-637.5277), alpha=tensor(0.5727)\n",
      "Accepting with params: f_xn=tensor(-637.5339), f_x0=tensor(-637.5743), alpha=tensor(0.6247)\n",
      "Accepting with params: f_xn=tensor(-637.4727), f_x0=tensor(-637.5339), alpha=tensor(0.6379)\n",
      "Accepting with params: f_xn=tensor(-638.0192), f_x0=tensor(-637.4727), alpha=tensor(0.3474)\n",
      "Accepting with params: f_xn=tensor(-638.3964), f_x0=tensor(-638.0192), alpha=tensor(0.4114)\n",
      "Accepting with params: f_xn=tensor(-638.9777), f_x0=tensor(-638.3964), alpha=tensor(0.3355)\n",
      "Accepting with params: f_xn=tensor(-638.0477), f_x0=tensor(-638.9777), alpha=tensor(1.5207)\n",
      "Accepting with params: f_xn=tensor(-637.7582), f_x0=tensor(-638.0477), alpha=tensor(0.8014)\n",
      "Accepting with params: f_xn=tensor(-637.6531), f_x0=tensor(-637.7582), alpha=tensor(0.6665)\n",
      "Accepting with params: f_xn=tensor(-636.5370), f_x0=tensor(-637.6531), alpha=tensor(1.8318)\n",
      "Accepting with params: f_xn=tensor(-636.7205), f_x0=tensor(-636.5370), alpha=tensor(0.4994)\n",
      "Accepting with params: f_xn=tensor(-637.3506), f_x0=tensor(-636.7205), alpha=tensor(0.3195)\n",
      "Accepting with params: f_xn=tensor(-638.1770), f_x0=tensor(-637.3506), alpha=tensor(0.2626)\n",
      "Accepting with params: f_xn=tensor(-637.3024), f_x0=tensor(-638.1770), alpha=tensor(1.4388)\n",
      "Accepting with params: f_xn=tensor(-637.3403), f_x0=tensor(-637.3024), alpha=tensor(0.5776)\n",
      "Accepting with params: f_xn=tensor(-637.0546), f_x0=tensor(-637.3403), alpha=tensor(0.7984)\n",
      "Accepting with params: f_xn=tensor(-636.9354), f_x0=tensor(-637.0546), alpha=tensor(0.6760)\n",
      "Accepting with params: f_xn=tensor(-638.0991), f_x0=tensor(-636.9354), alpha=tensor(0.1874)\n",
      "Accepting with params: f_xn=tensor(-636.2955), f_x0=tensor(-638.0991), alpha=tensor(3.6428)\n",
      "Accepting with params: f_xn=tensor(-636.0844), f_x0=tensor(-636.2955), alpha=tensor(0.7411)\n",
      "Accepting with params: f_xn=tensor(-636.3882), f_x0=tensor(-636.0844), alpha=tensor(0.4428)\n",
      "Accepting with params: f_xn=tensor(-637.2465), f_x0=tensor(-636.3882), alpha=tensor(0.2543)\n",
      "Accepting with params: f_xn=tensor(-635.6008), f_x0=tensor(-637.2465), alpha=tensor(3.1108)\n",
      "Accepting with params: f_xn=tensor(-635.5450), f_x0=tensor(-635.6008), alpha=tensor(0.6344)\n",
      "Accepting with params: f_xn=tensor(-635.5967), f_x0=tensor(-635.5450), alpha=tensor(0.5698)\n",
      "Accepting with params: f_xn=tensor(-636.7752), f_x0=tensor(-635.5967), alpha=tensor(0.1846)\n",
      "Accepting with params: f_xn=tensor(-636.7655), f_x0=tensor(-636.7752), alpha=tensor(0.6059)\n",
      "Accepting with params: f_xn=tensor(-636.7368), f_x0=tensor(-636.7655), alpha=tensor(0.6175)\n",
      "Accepting with params: f_xn=tensor(-637.1445), f_x0=tensor(-636.7368), alpha=tensor(0.3991)\n",
      "Accepting with params: f_xn=tensor(-637.0390), f_x0=tensor(-637.1445), alpha=tensor(0.6667)\n",
      "Accepting with params: f_xn=tensor(-636.9981), f_x0=tensor(-637.0390), alpha=tensor(0.6250)\n",
      "Accepting with params: f_xn=tensor(-637.3305), f_x0=tensor(-636.9981), alpha=tensor(0.4303)\n",
      "Accepting with params: f_xn=tensor(-637.4177), f_x0=tensor(-637.3305), alpha=tensor(0.5499)\n",
      "Accepting with params: f_xn=tensor(-637.9434), f_x0=tensor(-637.4177), alpha=tensor(0.3547)\n",
      "Accepting with params: f_xn=tensor(-637.1603), f_x0=tensor(-637.9434), alpha=tensor(1.3130)\n",
      "Accepting with params: f_xn=tensor(-637.4694), f_x0=tensor(-637.1603), alpha=tensor(0.4404)\n",
      "Accepting with params: f_xn=tensor(-639.0986), f_x0=tensor(-637.4694), alpha=tensor(0.1177)\n",
      "Accepting with params: f_xn=tensor(-636.6674), f_x0=tensor(-639.0986), alpha=tensor(6.8236)\n",
      "Accepting with params: f_xn=tensor(-637.3077), f_x0=tensor(-636.6674), alpha=tensor(0.3163)\n",
      "Accepting with params: f_xn=tensor(-637.4710), f_x0=tensor(-637.3077), alpha=tensor(0.5096)\n",
      "Accepting with params: f_xn=tensor(-638.5632), f_x0=tensor(-637.4710), alpha=tensor(0.2013)\n",
      "Accepting with params: f_xn=tensor(-638.0026), f_x0=tensor(-638.5632), alpha=tensor(1.0511)\n",
      "Accepting with params: f_xn=tensor(-638.0060), f_x0=tensor(-638.0026), alpha=tensor(0.5979)\n",
      "Accepting with params: f_xn=tensor(-638.1419), f_x0=tensor(-638.0060), alpha=tensor(0.5238)\n",
      "Accepting with params: f_xn=tensor(-638.2919), f_x0=tensor(-638.1419), alpha=tensor(0.5164)\n",
      "Accepting with params: f_xn=tensor(-638.1100), f_x0=tensor(-638.2919), alpha=tensor(0.7197)\n",
      "Accepting with params: f_xn=tensor(-638.1398), f_x0=tensor(-638.1100), alpha=tensor(0.5824)\n",
      "Accepting with params: f_xn=tensor(-638.2523), f_x0=tensor(-638.1398), alpha=tensor(0.5362)\n",
      "Accepting with params: f_xn=tensor(-637.6939), f_x0=tensor(-638.2523), alpha=tensor(1.0487)\n",
      "Accepting with params: f_xn=tensor(-638.2245), f_x0=tensor(-637.6939), alpha=tensor(0.3530)\n",
      "Accepting with params: f_xn=tensor(-638.4257), f_x0=tensor(-638.2245), alpha=tensor(0.4906)\n",
      "Accepting with params: f_xn=tensor(-638.2604), f_x0=tensor(-638.4257), alpha=tensor(0.7079)\n",
      "Accepting with params: f_xn=tensor(-638.7843), f_x0=tensor(-638.2604), alpha=tensor(0.3553)\n",
      "Accepting with params: f_xn=tensor(-639.1696), f_x0=tensor(-638.7843), alpha=tensor(0.4081)\n",
      "Accepting with params: f_xn=tensor(-639.6562), f_x0=tensor(-639.1696), alpha=tensor(0.3688)\n",
      "Accepting with params: f_xn=tensor(-639.9137), f_x0=tensor(-639.6562), alpha=tensor(0.4638)\n",
      "Accepting with params: f_xn=tensor(-640.7891), f_x0=tensor(-639.9137), alpha=tensor(0.2500)\n",
      "Accepting with params: f_xn=tensor(-639.2524), f_x0=tensor(-640.7891), alpha=tensor(2.7895)\n",
      "Accepting with params: f_xn=tensor(-639.5096), f_x0=tensor(-639.2524), alpha=tensor(0.4639)\n",
      "Accepting with params: f_xn=tensor(-640.2565), f_x0=tensor(-639.5096), alpha=tensor(0.2843)\n",
      "Accepting with params: f_xn=tensor(-638.7018), f_x0=tensor(-640.2565), alpha=tensor(2.8402)\n",
      "Accepting with params: f_xn=tensor(-638.4106), f_x0=tensor(-638.7018), alpha=tensor(0.8028)\n",
      "Accepting with params: f_xn=tensor(-638.3839), f_x0=tensor(-638.4106), alpha=tensor(0.6163)\n",
      "Accepting with params: f_xn=tensor(-640.8340), f_x0=tensor(-638.3839), alpha=tensor(0.0518)\n",
      "Accepting with params: f_xn=tensor(-639.3473), f_x0=tensor(-640.8340), alpha=tensor(2.6536)\n",
      "Accepting with params: f_xn=tensor(-638.8363), f_x0=tensor(-639.3473), alpha=tensor(1.0002)\n",
      "Accepting with params: f_xn=tensor(-639.4167), f_x0=tensor(-638.8363), alpha=tensor(0.3358)\n",
      "Accepting with params: f_xn=tensor(-639.2553), f_x0=tensor(-639.4167), alpha=tensor(0.7051)\n",
      "Accepting with params: f_xn=tensor(-638.5756), f_x0=tensor(-639.2553), alpha=tensor(1.1840)\n",
      "Accepting with params: f_xn=tensor(-638.5343), f_x0=tensor(-638.5756), alpha=tensor(0.6253)\n",
      "Accepting with params: f_xn=tensor(-637.5826), f_x0=tensor(-638.5343), alpha=tensor(1.5541)\n",
      "Accepting with params: f_xn=tensor(-637.5795), f_x0=tensor(-637.5826), alpha=tensor(0.6019)\n",
      "Accepting with params: f_xn=tensor(-638.2145), f_x0=tensor(-637.5795), alpha=tensor(0.3179)\n",
      "Accepting with params: f_xn=tensor(-637.4940), f_x0=tensor(-638.2145), alpha=tensor(1.2333)\n",
      "Accepting with params: f_xn=tensor(-638.3935), f_x0=tensor(-637.4940), alpha=tensor(0.2441)\n",
      "Accepting with params: f_xn=tensor(-637.5549), f_x0=tensor(-638.3935), alpha=tensor(1.3878)\n",
      "Accepting with params: f_xn=tensor(-637.7398), f_x0=tensor(-637.5549), alpha=tensor(0.4987)\n",
      "Accepting with params: f_xn=tensor(-636.9824), f_x0=tensor(-637.7398), alpha=tensor(1.2797)\n",
      "Accepting with params: f_xn=tensor(-637.3022), f_x0=tensor(-636.9824), alpha=tensor(0.4358)\n",
      "Accepting with params: f_xn=tensor(-637.1491), f_x0=tensor(-637.3022), alpha=tensor(0.6992)\n",
      "Accepting with params: f_xn=tensor(-640.1407), f_x0=tensor(-637.1491), alpha=tensor(0.0301)\n",
      "Accepting with params: f_xn=tensor(-638.7211), f_x0=tensor(-640.1407), alpha=tensor(2.4812)\n",
      "Accepting with params: f_xn=tensor(-638.7894), f_x0=tensor(-638.7211), alpha=tensor(0.5604)\n",
      "Accepting with params: f_xn=tensor(-637.3160), f_x0=tensor(-638.7894), alpha=tensor(2.6184)\n",
      "Accepting with params: f_xn=tensor(-637.4773), f_x0=tensor(-637.3160), alpha=tensor(0.5106)\n",
      "Accepting with params: f_xn=tensor(-637.4873), f_x0=tensor(-637.4773), alpha=tensor(0.5940)\n",
      "Accepting with params: f_xn=tensor(-636.6957), f_x0=tensor(-637.4873), alpha=tensor(1.3242)\n",
      "Accepting with params: f_xn=tensor(-636.8412), f_x0=tensor(-636.6957), alpha=tensor(0.5187)\n",
      "Accepting with params: f_xn=tensor(-636.7081), f_x0=tensor(-636.8412), alpha=tensor(0.6854)\n",
      "Accepting with params: f_xn=tensor(-637.5349), f_x0=tensor(-636.7081), alpha=tensor(0.2625)\n",
      "Accepting with params: f_xn=tensor(-637.8133), f_x0=tensor(-637.5349), alpha=tensor(0.4542)\n",
      "Accepting with params: f_xn=tensor(-637.8182), f_x0=tensor(-637.8133), alpha=tensor(0.5971)\n",
      "Accepting with params: f_xn=tensor(-638.3645), f_x0=tensor(-637.8182), alpha=tensor(0.3474)\n",
      "Accepting with params: f_xn=tensor(-638.1450), f_x0=tensor(-638.3645), alpha=tensor(0.7473)\n",
      "Accepting with params: f_xn=tensor(-637.6565), f_x0=tensor(-638.1450), alpha=tensor(0.9779)\n",
      "Accepting with params: f_xn=tensor(-639.6292), f_x0=tensor(-637.6565), alpha=tensor(0.0835)\n",
      "Accepting with params: f_xn=tensor(-637.6479), f_x0=tensor(-639.6292), alpha=tensor(4.3511)\n",
      "Accepting with params: f_xn=tensor(-638.0043), f_x0=tensor(-637.6479), alpha=tensor(0.4201)\n",
      "Accepting with params: f_xn=tensor(-637.4496), f_x0=tensor(-638.0043), alpha=tensor(1.0449)\n",
      "Accepting with params: f_xn=tensor(-637.4109), f_x0=tensor(-637.4496), alpha=tensor(0.6237)\n",
      "Accepting with params: f_xn=tensor(-637.1805), f_x0=tensor(-637.4109), alpha=tensor(0.7555)\n",
      "Accepting with params: f_xn=tensor(-636.2526), f_x0=tensor(-637.1805), alpha=tensor(1.5175)\n",
      "Accepting with params: f_xn=tensor(-637.7462), f_x0=tensor(-636.2526), alpha=tensor(0.1347)\n",
      "Accepting with params: f_xn=tensor(-636.9390), f_x0=tensor(-637.7462), alpha=tensor(1.3450)\n",
      "Accepting with params: f_xn=tensor(-637.7891), f_x0=tensor(-636.9390), alpha=tensor(0.2564)\n",
      "Accepting with params: f_xn=tensor(-637.3785), f_x0=tensor(-637.7891), alpha=tensor(0.9046)\n",
      "Accepting with params: f_xn=tensor(-637.3148), f_x0=tensor(-637.3785), alpha=tensor(0.6395)\n",
      "Accepting with params: f_xn=tensor(-637.3141), f_x0=tensor(-637.3148), alpha=tensor(0.6004)\n",
      "Accepting with params: f_xn=tensor(-636.7869), f_x0=tensor(-637.3141), alpha=tensor(1.0166)\n",
      "Accepting with params: f_xn=tensor(-636.9804), f_x0=tensor(-636.7869), alpha=tensor(0.4944)\n",
      "Accepting with params: f_xn=tensor(-636.5874), f_x0=tensor(-636.9804), alpha=tensor(0.8889)\n",
      "Accepting with params: f_xn=tensor(-637.9218), f_x0=tensor(-636.5874), alpha=tensor(0.1580)\n",
      "Accepting with params: f_xn=tensor(-637.0508), f_x0=tensor(-637.9218), alpha=tensor(1.4335)\n",
      "Accepting with params: f_xn=tensor(-637.6195), f_x0=tensor(-637.0508), alpha=tensor(0.3398)\n",
      "Accepting with params: f_xn=tensor(-638.2643), f_x0=tensor(-637.6195), alpha=tensor(0.3148)\n",
      "Accepting with params: f_xn=tensor(-637.3847), f_x0=tensor(-638.2643), alpha=tensor(1.4460)\n",
      "Accepting with params: f_xn=tensor(-637.1515), f_x0=tensor(-637.3847), alpha=tensor(0.7576)\n",
      "Accepting with params: f_xn=tensor(-638.8521), f_x0=tensor(-637.1515), alpha=tensor(0.1095)\n",
      "Accepting with params: f_xn=tensor(-638.4147), f_x0=tensor(-638.8521), alpha=tensor(0.9292)\n",
      "Accepting with params: f_xn=tensor(-637.6417), f_x0=tensor(-638.4147), alpha=tensor(1.2997)\n",
      "Accepting with params: f_xn=tensor(-639.1458), f_x0=tensor(-637.6417), alpha=tensor(0.1333)\n",
      "Accepting with params: f_xn=tensor(-637.0834), f_x0=tensor(-639.1458), alpha=tensor(4.7188)\n",
      "Accepting with params: f_xn=tensor(-637.0144), f_x0=tensor(-637.0834), alpha=tensor(0.6429)\n",
      "Accepting with params: f_xn=tensor(-637.1561), f_x0=tensor(-637.0144), alpha=tensor(0.5207)\n",
      "Accepting with params: f_xn=tensor(-636.1848), f_x0=tensor(-637.1561), alpha=tensor(1.5849)\n",
      "Accepting with params: f_xn=tensor(-636.0983), f_x0=tensor(-636.1848), alpha=tensor(0.6542)\n",
      "Accepting with params: f_xn=tensor(-637.3405), f_x0=tensor(-636.0983), alpha=tensor(0.1733)\n",
      "Accepting with params: f_xn=tensor(-637.9318), f_x0=tensor(-637.3405), alpha=tensor(0.3321)\n",
      "Accepting with params: f_xn=tensor(-637.3952), f_x0=tensor(-637.9318), alpha=tensor(1.0261)\n",
      "Accepting with params: f_xn=tensor(-638.1840), f_x0=tensor(-637.3952), alpha=tensor(0.2726)\n",
      "Accepting with params: f_xn=tensor(-637.8425), f_x0=tensor(-638.1840), alpha=tensor(0.8442)\n",
      "Accepting with params: f_xn=tensor(-637.9890), f_x0=tensor(-637.8425), alpha=tensor(0.5182)\n",
      "Accepting with params: f_xn=tensor(-638.2918), f_x0=tensor(-637.9890), alpha=tensor(0.4433)\n",
      "Accepting with params: f_xn=tensor(-638.3580), f_x0=tensor(-638.2918), alpha=tensor(0.5616)\n",
      "Accepting with params: f_xn=tensor(-638.2375), f_x0=tensor(-638.3580), alpha=tensor(0.6768)\n",
      "Accepting with params: f_xn=tensor(-637.7277), f_x0=tensor(-638.2375), alpha=tensor(0.9990)\n",
      "Accepting with params: f_xn=tensor(-638.0186), f_x0=tensor(-637.7277), alpha=tensor(0.4486)\n",
      "Accepting with params: f_xn=tensor(-637.1157), f_x0=tensor(-638.0186), alpha=tensor(1.4801)\n",
      "Accepting with params: f_xn=tensor(-637.4061), f_x0=tensor(-637.1157), alpha=tensor(0.4488)\n",
      "Accepting with params: f_xn=tensor(-636.8263), f_x0=tensor(-637.4061), alpha=tensor(1.0714)\n",
      "Accepting with params: f_xn=tensor(-636.7762), f_x0=tensor(-636.8263), alpha=tensor(0.6308)\n",
      "Accepting with params: f_xn=tensor(-637.0280), f_x0=tensor(-636.7762), alpha=tensor(0.4664)\n",
      "Accepting with params: f_xn=tensor(-636.8840), f_x0=tensor(-637.0280), alpha=tensor(0.6930)\n",
      "Accepting with params: f_xn=tensor(-637.4676), f_x0=tensor(-636.8840), alpha=tensor(0.3347)\n",
      "Accepting with params: f_xn=tensor(-636.8911), f_x0=tensor(-637.4676), alpha=tensor(1.0679)\n",
      "Accepting with params: f_xn=tensor(-636.6696), f_x0=tensor(-636.8911), alpha=tensor(0.7488)\n",
      "Accepting with params: f_xn=tensor(-637.1945), f_x0=tensor(-636.6696), alpha=tensor(0.3550)\n",
      "Accepting with params: f_xn=tensor(-637.5970), f_x0=tensor(-637.1945), alpha=tensor(0.4012)\n",
      "Accepting with params: f_xn=tensor(-637.4897), f_x0=tensor(-637.5970), alpha=tensor(0.6679)\n",
      "Accepting with params: f_xn=tensor(-636.4879), f_x0=tensor(-637.4897), alpha=tensor(1.6341)\n",
      "Accepting with params: f_xn=tensor(-637.3225), f_x0=tensor(-636.4879), alpha=tensor(0.2604)\n",
      "Accepting with params: f_xn=tensor(-636.0151), f_x0=tensor(-637.3225), alpha=tensor(2.2179)\n",
      "Accepting with params: f_xn=tensor(-636.9760), f_x0=tensor(-636.0151), alpha=tensor(0.2295)\n",
      "Accepting with params: f_xn=tensor(-636.8919), f_x0=tensor(-636.9760), alpha=tensor(0.6526)\n",
      "Accepting with params: f_xn=tensor(-636.6162), f_x0=tensor(-636.8919), alpha=tensor(0.7905)\n",
      "Accepting with params: f_xn=tensor(-634.6917), f_x0=tensor(-636.6162), alpha=tensor(4.1113)\n",
      "Accepting with params: f_xn=tensor(-634.2129), f_x0=tensor(-634.6917), alpha=tensor(0.9684)\n",
      "Accepting with params: f_xn=tensor(-634.2832), f_x0=tensor(-634.2129), alpha=tensor(0.5593)\n",
      "Accepting with params: f_xn=tensor(-634.4105), f_x0=tensor(-634.2832), alpha=tensor(0.5283)\n",
      "Accepting with params: f_xn=tensor(-635.4873), f_x0=tensor(-634.4105), alpha=tensor(0.2044)\n",
      "Accepting with params: f_xn=tensor(-634.8398), f_x0=tensor(-635.4873), alpha=tensor(1.1464)\n",
      "Accepting with params: f_xn=tensor(-634.7062), f_x0=tensor(-634.8398), alpha=tensor(0.6858)\n",
      "Accepting with params: f_xn=tensor(-633.9038), f_x0=tensor(-634.7062), alpha=tensor(1.3385)\n",
      "Accepting with params: f_xn=tensor(-634.2811), f_x0=tensor(-633.9038), alpha=tensor(0.4114)\n",
      "Accepting with params: f_xn=tensor(-634.4194), f_x0=tensor(-634.2811), alpha=tensor(0.5225)\n",
      "Accepting with params: f_xn=tensor(-634.6810), f_x0=tensor(-634.4194), alpha=tensor(0.4619)\n",
      "Accepting with params: f_xn=tensor(-635.2427), f_x0=tensor(-634.6810), alpha=tensor(0.3422)\n",
      "Accepting with params: f_xn=tensor(-634.2673), f_x0=tensor(-635.2427), alpha=tensor(1.5912)\n",
      "Accepting with params: f_xn=tensor(-634.6327), f_x0=tensor(-634.2673), alpha=tensor(0.4164)\n",
      "Accepting with params: f_xn=tensor(-634.7573), f_x0=tensor(-634.6327), alpha=tensor(0.5297)\n",
      "Accepting with params: f_xn=tensor(-634.0303), f_x0=tensor(-634.7573), alpha=tensor(1.2412)\n",
      "Accepting with params: f_xn=tensor(-633.4771), f_x0=tensor(-634.0303), alpha=tensor(1.0433)\n",
      "Accepting with params: f_xn=tensor(-634.1106), f_x0=tensor(-633.4771), alpha=tensor(0.3184)\n",
      "Accepting with params: f_xn=tensor(-635.1750), f_x0=tensor(-634.1106), alpha=tensor(0.2070)\n",
      "Accepting with params: f_xn=tensor(-634.7069), f_x0=tensor(-635.1750), alpha=tensor(0.9582)\n",
      "CPU times: user 3.06 s, sys: 14 ms, total: 3.08 s\n",
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "big_tetha = metropolis_for_model(\n",
    "    linear,\n",
    "    stats.norm(-0.2, 0.4).cdf,  # taken from the distribution of trained weights\n",
    "    X, y,\n",
    "    # stats.uniform(-0.2, 0.4).rvs(sum(p.numel() for p in linear.parameters() if p.requires_grad)),\n",
    "    params,  # start searching around the trained model\n",
    "    10_000,\n",
    "    burnin=1000,\n",
    "    scale=0.6,  # flatten the distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a04ebc1d-b972-4087-b88a-f65e500dc617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_tetha)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76478a78-b047-4182-92d7-4679455b0fa9",
   "metadata": {},
   "source": [
    "min_loss = 10 ** 10\n",
    "min_idx = 0\n",
    "for idx, (p, _) in enumerate(final_model):\n",
    "    load_params_in_model(linear, p)\n",
    "    loss = torch.nn.functional.cross_entropy(linear(X).softmax(1), y).item()\n",
    "    if loss < min_loss:\n",
    "        print(\"New min: \", loss, \"at index \", idx)\n",
    "        min_loss = loss\n",
    "        min_idx = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bc910-3005-491c-8e58-5f78852e401b",
   "metadata": {},
   "source": [
    "## Unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1c7d257-fc0f-4ad9-b4d6-96a738bc4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the erase (or forget) set\n",
    "\n",
    "to_unlearn = torch.randint(0, len(X), (50, ))\n",
    "idxs = torch.ones(len(X), dtype=bool)\n",
    "idxs[to_unlearn] = False\n",
    "X_r, y_r = X[idxs], y[idxs]\n",
    "X_e, y_e = X[~idxs], y[~idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd4758a-ea02-463a-9012-f012b1d80bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 20]),\n",
       " torch.Size([48]),\n",
       " torch.Size([857, 20]),\n",
       " torch.Size([857]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_e.shape, y_e.shape, X_r.shape, y_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129d97f6-a834-4d20-acaf-bd1282f91253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_model_params(model, get_only_grads=True):\n",
    "    \"\"\"Extract all the weights from `model` as numpy flatten array.\"\"\"\n",
    "    params = torch.concat([p.flatten() for p in model.parameters() if get_only_grads and p.requires_grad])\n",
    "    return params.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fc408c3-392c-4e58-9435-e4a816cfe5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best scoring model according to the provided forget set.\n",
    "# The computation find the theta that maximize the following formula:\n",
    "#        g(theta, D_e) - log(p(D_r))\n",
    "# which can be simplified as:\n",
    "#        h(theta) - log(p(D_e | theta))    ; no more D_r, since it's indipendent from theta\n",
    "\n",
    "largest = -1 * 10 ** 10\n",
    "old_params = get_numpy_model_params(linear)\n",
    "max_idx = 0\n",
    "\n",
    "for idx, (w, h_tetha) in enumerate(big_tetha):\n",
    "    load_params_in_model(linear, w)\n",
    "    probs = linear(X_e).softmax(1).gather(1, y_e.unsqueeze(1)).log().sum()\n",
    "    g = h_tetha - probs\n",
    "    if g > largest:\n",
    "        # print(\"New largest \", g, \"at idx\", idx)\n",
    "        largest = g\n",
    "        max_idx = idx\n",
    "\n",
    "load_params_in_model(linear, old_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a02e82fe-d259-4d06-8faf-0b52b3c2393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_params_in_model(linear, big_tetha[max_idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51738ab2-6137-4503-825e-473346649d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5403)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(linear, X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38d19f4a-3e57-471a-a7c4-fc5e3838a686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7658620476722717\r"
     ]
    }
   ],
   "source": [
    "scratch = torch.nn.Linear(20, 2)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for _ in range(epochs):\n",
    "    preds = scratch(X_r)\n",
    "    preds = preds.softmax(1).max(1)[0]\n",
    "    loss = loss_fn(preds, y_r.float())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"loss: {}\\r\".format(loss.item()), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac5be5ea-b8b5-40c5-80d8-eb4ecb67fc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4761)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(scratch, X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "025d522e-6021-4897-934d-89cc3c4c4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(net, d_x, d_y):\n",
    "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    all_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "            # inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        logits = net(d_x)\n",
    "        losses = criterion(logits, d_y).numpy(force=True)\n",
    "        for l in losses:\n",
    "            all_losses.append(l)\n",
    "\n",
    "    return np.array(all_losses)\n",
    "\n",
    "\n",
    "# train_losses = compute_losses(model, train_loader)\n",
    "# test_losses = compute_losses(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34817f5c-92c8-4722-904c-40a25c5fe677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metropolis_Model_Unlearner:\n",
    "    def __init__(self, model, params_cdf, proposal_fn=\"normal\", delta=0.3):\n",
    "        # Model info\n",
    "        self.model = model\n",
    "        # self._backup_weights = get_numpy_model_params(model, get_only_grads=True)\n",
    "        self.total_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "        # Metropolis info\n",
    "        self.params_cdf = params_cdf\n",
    "        if proposal_fn == \"normal\":\n",
    "            self.proposal = stats.norm(0, delta)\n",
    "        elif proposal_fn == \"uniform\":\n",
    "            self.proposal = stats.uniform(-delta, 2*delta)\n",
    "        else:\n",
    "            raise ValueError(\"invalid proposal fn '{}'\".format(proposal_fn))\n",
    "        assert self.proposal is not None\n",
    "        # self.noise = stats.norm(0, 0.3)  # also valid stats.uniform(-0.1, 0.2)\n",
    "        self.steps = 0\n",
    "\n",
    "\n",
    "    def generate_best_model(self, d_x, d_y, e_x, e_y, early_stopping=100, scale=1.0):\n",
    "        best_score = -1 * 10 ** 10\n",
    "\n",
    "        x0 = get_numpy_model_params(self.model)\n",
    "        f_x0 = self.h_function(x0, d_x, d_y)\n",
    "        best_weight = x0\n",
    "\n",
    "        stop = 0\n",
    "        while stop <= early_stopping:\n",
    "            stop += 1\n",
    "            self.steps += 1\n",
    "\n",
    "            x_n = x0 + self.proposal.rvs(self.total_param)\n",
    "            f_xn = self.h_function(x_n, d_x, d_y)\n",
    "\n",
    "            alpha = np.exp(f_xn - f_x0) * scale\n",
    "\n",
    "            u = np.random.uniform(0, 1)  # @Speed: precompute\n",
    "            if u <= alpha:\n",
    "                # print(\"   debug: improving\")\n",
    "                # Accept\n",
    "                x0 = x_n\n",
    "                f_x0 = f_xn\n",
    "                # Find if this is a suitable value for the erase set.\n",
    "                with torch.no_grad():\n",
    "                    e_prob = self.model(e_x).softmax(1).gather(\n",
    "                        1, e_y.unsqueeze(1)).log().sum()\n",
    "                    g = f_xn - e_prob\n",
    "                if g > best_score:\n",
    "                    print(\"  DEBUG: new best score\", g)\n",
    "                    best_score = g\n",
    "                    best_weight = x_n\n",
    "                    stop = 0\n",
    "\n",
    "        return best_weight, best_score\n",
    "\n",
    "\n",
    "    def h_function(self, theta, d_x, d_y):\n",
    "        load_params_in_model(self.model, theta)\n",
    "        with torch.no_grad():\n",
    "            p_dataset = self.model(d_x).softmax(1).gather(1, d_y.unsqueeze(1)).log().sum()\n",
    "            p_weights = np.log(self.params_cdf(theta)).sum()\n",
    "            return p_dataset + p_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77bf5d83-4e17-409a-b97b-90320566c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_params_in_model(linear, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa9e8b6c-9d79-475e-b2e5-027b4815178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Metropolis_Model_Unlearner(\n",
    "    linear,\n",
    "    stats.uniform(-0.2, 0.4).cdf,\n",
    "    proposal_fn=\"normal\",\n",
    "    delta=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48530bfa-eaee-41fb-a66e-2a5de12497c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7918/118471589.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  p_weights = np.log(self.params_cdf(theta)).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DEBUG: new best score tensor(-686.7079)\n",
      "  DEBUG: new best score tensor(-636.9696)\n",
      "  DEBUG: new best score tensor(-622.7790)\n",
      "  DEBUG: new best score tensor(-611.2457)\n",
      "  DEBUG: new best score tensor(-578.1829)\n",
      "  DEBUG: new best score tensor(-558.7150)\n",
      "  DEBUG: new best score tensor(-546.1091)\n",
      "  DEBUG: new best score tensor(-527.3767)\n",
      "  DEBUG: new best score tensor(-506.7711)\n",
      "  DEBUG: new best score tensor(-491.4445)\n",
      "  DEBUG: new best score tensor(-488.1906)\n",
      "  DEBUG: new best score tensor(-483.3107)\n",
      "  DEBUG: new best score tensor(-469.2409)\n",
      "  DEBUG: new best score tensor(-457.1782)\n",
      "  DEBUG: new best score tensor(-434.6732)\n",
      "  DEBUG: new best score tensor(-430.7705)\n",
      "  DEBUG: new best score tensor(-413.5713)\n",
      "  DEBUG: new best score tensor(-410.4002)\n",
      "  DEBUG: new best score tensor(-401.7427)\n",
      "  DEBUG: new best score tensor(-397.4849)\n",
      "  DEBUG: new best score tensor(-393.6765)\n",
      "  DEBUG: new best score tensor(-385.5323)\n",
      "  DEBUG: new best score tensor(-377.8654)\n",
      "  DEBUG: new best score tensor(-372.0103)\n",
      "  DEBUG: new best score tensor(-369.6998)\n",
      "  DEBUG: new best score tensor(-369.3266)\n",
      "  DEBUG: new best score tensor(-364.3042)\n",
      "  DEBUG: new best score tensor(-354.8290)\n",
      "  DEBUG: new best score tensor(-348.3157)\n",
      "  DEBUG: new best score tensor(-347.6932)\n",
      "  DEBUG: new best score tensor(-345.2388)\n",
      "  DEBUG: new best score tensor(-338.4726)\n",
      "  DEBUG: new best score tensor(-332.3874)\n",
      "  DEBUG: new best score tensor(-332.0900)\n",
      "  DEBUG: new best score tensor(-327.0837)\n",
      "  DEBUG: new best score tensor(-326.1895)\n",
      "  DEBUG: new best score tensor(-324.9735)\n",
      "  DEBUG: new best score tensor(-318.8292)\n",
      "  DEBUG: new best score tensor(-311.5552)\n",
      "  DEBUG: new best score tensor(-310.8044)\n",
      "  DEBUG: new best score tensor(-305.5309)\n",
      "  DEBUG: new best score tensor(-300.5847)\n",
      "  DEBUG: new best score tensor(-299.5305)\n",
      "  DEBUG: new best score tensor(-297.3847)\n",
      "  DEBUG: new best score tensor(-296.0113)\n",
      "  DEBUG: new best score tensor(-288.1548)\n",
      "  DEBUG: new best score tensor(-285.5473)\n",
      "  DEBUG: new best score tensor(-284.6897)\n",
      "  DEBUG: new best score tensor(-281.1981)\n",
      "  DEBUG: new best score tensor(-280.9397)\n",
      "  DEBUG: new best score tensor(-279.4587)\n",
      "  DEBUG: new best score tensor(-277.9371)\n",
      "  DEBUG: new best score tensor(-275.9267)\n",
      "  DEBUG: new best score tensor(-275.5941)\n",
      "  DEBUG: new best score tensor(-274.1556)\n",
      "  DEBUG: new best score tensor(-272.1084)\n",
      "  DEBUG: new best score tensor(-270.6235)\n",
      "  DEBUG: new best score tensor(-270.0832)\n",
      "  DEBUG: new best score tensor(-269.3755)\n",
      "  DEBUG: new best score tensor(-269.1067)\n",
      "  DEBUG: new best score tensor(-266.0694)\n",
      "  DEBUG: new best score tensor(-265.0506)\n",
      "  DEBUG: new best score tensor(-264.6799)\n",
      "  DEBUG: new best score tensor(-263.0590)\n",
      "  DEBUG: new best score tensor(-260.3035)\n",
      "  DEBUG: new best score tensor(-260.0369)\n",
      "  DEBUG: new best score tensor(-259.0394)\n",
      "  DEBUG: new best score tensor(-258.4830)\n",
      "  DEBUG: new best score tensor(-257.7247)\n",
      "  DEBUG: new best score tensor(-256.4037)\n",
      "  DEBUG: new best score tensor(-254.7101)\n",
      "  DEBUG: new best score tensor(-254.6348)\n",
      "  DEBUG: new best score tensor(-254.4450)\n",
      "  DEBUG: new best score tensor(-254.2654)\n",
      "  DEBUG: new best score tensor(-254.1345)\n",
      "  DEBUG: new best score tensor(-254.0990)\n",
      "  DEBUG: new best score tensor(-253.9244)\n"
     ]
    }
   ],
   "source": [
    "best_weight, score = m.generate_best_model(X_r, y_r, X_e, y_e, early_stopping=20_000, scale=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3480188c-5b34-4d8b-b1b5-9350a148ab28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.87744142, 2.46639348, 1.214464  , 2.71645984, 3.10896223,\n",
       "        3.41630694, 2.74614609, 2.39566966, 3.93139955, 3.49908288,\n",
       "        1.68172047, 1.17362182, 2.47525358, 3.32265605, 0.49085358,\n",
       "        3.10161943, 3.22551122, 2.24575924, 1.05294824, 5.25658756,\n",
       "        4.11802572, 2.36878685, 1.26063794, 3.94478949, 0.76009825,\n",
       "        3.47250808, 2.89487809, 2.30942479, 3.9462162 , 3.42205509,\n",
       "        1.48757186, 1.10409852, 2.44866083, 3.32356518, 0.32311808,\n",
       "        5.50217258, 3.62810702, 2.3797927 , 0.98388338, 5.30626374,\n",
       "        2.11348585, 2.34852993]),\n",
       " tensor(-253.9244))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weight, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f42e0306-1eea-489f-b3a7-31582a3b47fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73883"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f11eced-2205-48a8-af2a-00c9143e607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_params_in_model(linear, best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "593a428c-befa-4bc4-b061-8ce924424e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8658)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(linear, X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "465a32a6-c8dd-48c2-b06a-8984a0be76ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4761)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(scratch, X_r, y_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a23c7-7227-4cd0-a135-00a1c0ca5455",
   "metadata": {},
   "source": [
    "## Experiments for the Hamiltonian MC (HMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebea84a8-1811-48b3-8bbc-abd29d302ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/martin-marek/mini-hmc-jax/blob/main/hmc.py\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def leapfrog(params, momentum, log_prob_fn, step_size, n_steps):\n",
    "    \"\"\"Approximates Hamiltonian dynamics using the leapfrog algorithm.\"\"\"\n",
    "\n",
    "    # define a single step\n",
    "    def step(i, args):\n",
    "        params, momentum = args\n",
    "        \n",
    "        # update momentum\n",
    "        grad = jax.grad(log_prob_fn)(params)\n",
    "        momentum += 0.5 * step_size * grad\n",
    "\n",
    "        # update params\n",
    "        params += momentum * step_size\n",
    "\n",
    "        # update momentum\n",
    "        grad = jax.grad(log_prob_fn)(params)\n",
    "        momentum += 0.5 * step_size * grad\n",
    "        \n",
    "        return params, momentum\n",
    "\n",
    "    # do 'n_steps'\n",
    "    new_params, new_momentum = jax.lax.fori_loop(0, n_steps, step, (params, momentum))\n",
    "\n",
    "    return new_params, new_momentum\n",
    "\n",
    "\n",
    "def sample(params, log_prob_fn, n_steps, n_leapfrog_steps, step_size, key):\n",
    "    \"\"\"\n",
    "    Runs HMC and returns the full Markov chain as a list.\n",
    "    - params: array\n",
    "    - log_prob_fn: function that takes params as the only argument and returns a scalar value\n",
    "    \"\"\"\n",
    "\n",
    "    # define a single step\n",
    "    def step(i, args):\n",
    "        params, chain, total_accept_prob, key = args\n",
    "        key, normal_key, uniform_key = jax.random.split(key, 3)\n",
    "\n",
    "        # generate random momentum\n",
    "        momentum = jax.random.normal(normal_key, shape=params.shape)\n",
    "\n",
    "        # leapfrog\n",
    "        new_params, new_momentum = leapfrog(params, momentum, log_prob_fn, step_size, n_leapfrog_steps)\n",
    "\n",
    "        # MH correction\n",
    "        potentaial_energy_diff = log_prob_fn(new_params) - log_prob_fn(params)\n",
    "        kinetic_energy_diff = 0.5*(momentum**2 - new_momentum**2).sum()\n",
    "        log_accept_prob = potentaial_energy_diff + kinetic_energy_diff\n",
    "        log_accept_prob = jnp.nan_to_num(log_accept_prob, nan=-jnp.inf)\n",
    "        accept_prob = jnp.minimum(1, jnp.exp(log_accept_prob))\n",
    "        total_accept_prob += accept_prob\n",
    "        accept = jax.random.uniform(uniform_key) < accept_prob\n",
    "        params = jnp.where(accept, new_params, params)\n",
    "        \n",
    "        # store params\n",
    "        chain = chain.at[i].set(params)\n",
    "         \n",
    "        return params, chain, total_accept_prob, key\n",
    "    \n",
    "    # do 'n_steps'\n",
    "    chain = jnp.zeros([n_steps, len(params)])\n",
    "    _, chain, total_accept_prob, key = jax.lax.fori_loop(0, n_steps, step, (params, chain, 0, key))\n",
    "    \n",
    "    print(f'Avg. accept. prob.: {(total_accept_prob/n_steps):.2%}')\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a86447d-aae7-4a75-af55-f25f5a3ec19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. accept. prob.: 99.43%\n"
     ]
    }
   ],
   "source": [
    "# define target distribution\n",
    "def target_log_pdf(params):\n",
    "    return jax.scipy.stats.t.logpdf(params, df=1).sum()\n",
    "\n",
    "# run HMC\n",
    "params_init = jnp.zeros(10)\n",
    "key = jax.random.PRNGKey(0)\n",
    "chain = sample(\n",
    "    params_init,\n",
    "    target_log_pdf,\n",
    "    n_steps=10,\n",
    "    n_leapfrog_steps=100,\n",
    "    step_size=0.1,\n",
    "    key=key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63d501b5-3e07-46f1-9e8c-6f27942341dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[2467461003,  428148500],\n",
       "       [3186719485, 3840466878],\n",
       "       [2562233961, 1946702221]], dtype=uint32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.random.split(key, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb185e87-e963-4664-9444-3654898cb291",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.rand_like(X)\n",
    "y_hat = linear(sample).max(axis=1)[0]\n",
    "grad = torch.autograd.grad(y_hat[0], linear.parameters(), create_graph=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4aa12bf1-afba-4aa7-8a6c-c35948448b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7636, 0.3352, 0.7362, 0.6920, 0.3123, 0.2430, 0.2489, 0.0351, 0.6320,\n",
       "        0.0354, 0.4619, 0.4316, 0.9835, 0.0685, 0.7778, 0.7311, 0.7433, 0.4512,\n",
       "        0.6874, 0.2272])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad[0][grad[1].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ecd1f9c-2ee4-40a8-8029-161afa232c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[435.4507, 464.1140, 458.1435, 440.4112, 444.0208, 453.4189, 457.2523,\n",
       "          465.1400, 452.8130, 453.8045, 449.2015, 438.1946, 453.3444, 448.9147,\n",
       "          456.7658, 449.6122, 443.3095, 446.7079, 457.8015, 461.5858],\n",
       "         [435.4507, 464.1140, 458.1435, 440.4112, 444.0208, 453.4189, 457.2523,\n",
       "          465.1400, 452.8130, 453.8045, 449.2015, 438.1946, 453.3444, 448.9147,\n",
       "          456.7658, 449.6122, 443.3095, 446.7079, 457.8015, 461.5858]]),\n",
       " tensor([905., 905.]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd3700-f2e8-439e-8843-2d0e7f732d25",
   "metadata": {},
   "source": [
    "## Unlearning quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5bb683df-9c4a-4d3d-9dec-5cc550e4fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, model_selection\n",
    "\n",
    "def simple_mia(sample_loss, members, n_splits=10, random_state=0):\n",
    "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
    "\n",
    "    Args:\n",
    "      sample_loss : array_like of shape (n,).\n",
    "        objective function evaluated on n samples.\n",
    "      members : array_like of shape (n,),\n",
    "        whether a sample was used for training.\n",
    "      n_splits: int\n",
    "        number of splits to use in the cross-validation.\n",
    "    Returns:\n",
    "      scores : array_like of size (n_splits,)\n",
    "    \"\"\"\n",
    "\n",
    "    unique_members = np.unique(members)\n",
    "    if not np.all(unique_members == np.array([0, 1])):\n",
    "        raise ValueError(\"members should only have 0 and 1s\")\n",
    "\n",
    "    attack_model = linear_model.LogisticRegression()\n",
    "    cv = model_selection.StratifiedShuffleSplit(\n",
    "        n_splits=n_splits, random_state=random_state\n",
    "    )\n",
    "    return model_selection.cross_val_score(\n",
    "        attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a15e5a4e-f2a2-421e-bb3e-0d21c997d530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MIA has an accuracy of 0.667 on forgotten vs unseen images\n"
     ]
    }
   ],
   "source": [
    "load_params_in_model(linear, best_weight)\n",
    "forget_losses = compute_losses(linear, X_e, y_e)\n",
    "test_losses   = compute_losses(linear, X_test, y_test)\n",
    "\n",
    "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
    "np.random.shuffle(forget_losses)\n",
    "forget_losses = forget_losses[: len(test_losses)]\n",
    "\n",
    "samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
    "labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
    "\n",
    "mia_scores = simple_mia(samples_mia, labels_mia)\n",
    "\n",
    "print(\n",
    "    f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbeddbe-322a-41f4-a407-214490318fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_params_in_model(linear, params)\n",
    "forget_losses = compute_losses(linear, X_e, y_e)\n",
    "test_losses   = compute_losses(linear, X_test, y_test)\n",
    "\n",
    "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
    "np.random.shuffle(forget_losses)\n",
    "forget_losses = forget_losses[: len(test_losses)]\n",
    "\n",
    "samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
    "labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
    "\n",
    "mia_scores = simple_mia(samples_mia, labels_mia)\n",
    "\n",
    "print(\n",
    "    f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a599410-96b9-4cc5-be76-a04cebfc6f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "72fe0a43-3cbb-4c1e-9305-9ba5ec365684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses on train and test set\n",
    "plt.title(\"Losses on train and test set (pre-trained model)\")\n",
    "plt.hist(test_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "plt.hist(train_losses, density=True, alpha=0.5, bins=50, label=\"Train set\")\n",
    "plt.xlabel(\"Loss\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.xlim((0, np.max(test_losses)))\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(frameon=False, fontsize=14)\n",
    "ax = plt.gca()\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89fd665-4295-4e91-b353-11759247ebf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2b514ac0-8b1f-4b9b-bf10-eb695d239831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 908 ms, sys: 3.05 ms, total: 911 ms\n",
      "Wall time: 908 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "got = metropolis(stats.expon().pdf, 1, 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e1eafd7b-37c6-4371-9a85-d540072a4523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1384., 1099.,  722.,  417.,  228.,  129.,   77.,   37.,   26.,\n",
       "           7.]),\n",
       " array([1.26711443e-03, 5.96117737e-01, 1.19096836e+00, 1.78581898e+00,\n",
       "        2.38066960e+00, 2.97552023e+00, 3.57037085e+00, 4.16522147e+00,\n",
       "        4.76007210e+00, 5.35492272e+00, 5.94977334e+00]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(got)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "31adccdd-55a8-4cb8-941b-2512df494595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.9573664795009253, pvalue=0.0852670409981493, statistic_location=-1.720910637454097, statistic_sign=1)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ks_1samp(stats.norm(0, 1).rvs(1), stats.norm(0, 1).cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1baf8-8a72-4081-be7c-6284352c196c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647993c-f0a8-455a-8f96-ce02e7e1c896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4dc1d1-ade8-43a0-8cce-1da72bf46815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b44dac-5d15-4789-b737-404d86c0d41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
